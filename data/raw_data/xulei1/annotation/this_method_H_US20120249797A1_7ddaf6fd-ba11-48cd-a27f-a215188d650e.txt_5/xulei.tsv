#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Diy_coref|
#T_RL=webanno.custom.Diy_coref_re|BT_webanno.custom.Diy_coref


#Text=[0909] It is to be understood that the vergence method embodiments include the placement of a virtual image for one of the user's eyes or for both of the user's eyes.
1-1	0-1	[	_	_	
1-2	1-5	0909	_	_	
1-3	5-6	]	_	_	
1-4	7-9	It	_	_	
1-5	10-12	is	_	_	
1-6	13-15	to	_	_	
1-7	16-18	be	_	_	
1-8	19-29	understood	_	_	
1-9	30-34	that	_	_	
1-10	35-38	the	_	_	
1-11	39-47	vergence	_	_	
1-12	48-54	method	_	_	
1-13	55-66	embodiments	_	_	
1-14	67-74	include	_	_	
1-15	75-78	the	_	_	
1-16	79-88	placement	_	_	
1-17	89-91	of	_	_	
1-18	92-93	a	_	_	
1-19	94-101	virtual	_	_	
1-20	102-107	image	_	_	
1-21	108-111	for	_	_	
1-22	112-115	one	_	_	
1-23	116-118	of	_	_	
1-24	119-122	the	_	_	
1-25	123-129	user's	_	_	
1-26	130-134	eyes	_	_	
1-27	135-137	or	_	_	
1-28	138-141	for	_	_	
1-29	142-146	both	_	_	
1-30	147-149	of	_	_	
1-31	150-153	the	_	_	
1-32	154-160	user's	_	_	
1-33	161-165	eyes	_	_	
1-34	165-166	.	_	_	

#Text=In some embodiments, one virtual image is provided to the user's left eye and a different virtual image is provided to the user's right eye.
2-1	167-169	In	_	_	
2-2	170-174	some	_	_	
2-3	175-186	embodiments	_	_	
2-4	186-187	,	_	_	
2-5	188-191	one	_	_	
2-6	192-199	virtual	_	_	
2-7	200-205	image	_	_	
2-8	206-208	is	_	_	
2-9	209-217	provided	_	_	
2-10	218-220	to	_	_	
2-11	221-224	the	_	_	
2-12	225-231	user's	_	_	
2-13	232-236	left	_	_	
2-14	237-240	eye	_	_	
2-15	241-244	and	_	_	
2-16	245-246	a	_	_	
2-17	247-256	different	_	_	
2-18	257-264	virtual	_	_	
2-19	265-270	image	_	_	
2-20	271-273	is	_	_	
2-21	274-282	provided	_	_	
2-22	283-285	to	_	_	
2-23	286-289	the	_	_	
2-24	290-296	user's	_	_	
2-25	297-302	right	_	_	
2-26	303-306	eye	_	_	
2-27	306-307	.	_	_	

#Text=In cases where multiple images are placed before the user, whether or not the images are the same or different, the placement may be simultaneous, at different times, or interlaced in time, e.g., the images are shown at a predetermined flicker rate or rates (e.g., 30, 60, and/or 180 Hz) with the image for the left eye being present when the image for the right eye is not and vice versa.
3-1	308-310	In	_	_	
3-2	311-316	cases	_	_	
3-3	317-322	where	_	_	
3-4	323-331	multiple	_	_	
3-5	332-338	images	_	_	
3-6	339-342	are	_	_	
3-7	343-349	placed	_	_	
3-8	350-356	before	_	_	
3-9	357-360	the	_	_	
3-10	361-365	user	_	_	
3-11	365-366	,	_	_	
3-12	367-374	whether	_	_	
3-13	375-377	or	_	_	
3-14	378-381	not	_	_	
3-15	382-385	the	_	_	
3-16	386-392	images	_	_	
3-17	393-396	are	_	_	
3-18	397-400	the	_	_	
3-19	401-405	same	_	_	
3-20	406-408	or	_	_	
3-21	409-418	different	_	_	
3-22	418-419	,	_	_	
3-23	420-423	the	_	_	
3-24	424-433	placement	_	_	
3-25	434-437	may	_	_	
3-26	438-440	be	_	_	
3-27	441-453	simultaneous	_	_	
3-28	453-454	,	_	_	
3-29	455-457	at	_	_	
3-30	458-467	different	_	_	
3-31	468-473	times	_	_	
3-32	473-474	,	_	_	
3-33	475-477	or	_	_	
3-34	478-488	interlaced	_	_	
3-35	489-491	in	_	_	
3-36	492-496	time	_	_	
3-37	496-497	,	_	_	
3-38	498-501	e.g	_	_	
3-39	501-502	.	_	_	
3-40	502-503	,	_	_	
3-41	504-507	the	_	_	
3-42	508-514	images	_	_	
3-43	515-518	are	_	_	
3-44	519-524	shown	_	_	
3-45	525-527	at	_	_	
3-46	528-529	a	_	_	
3-47	530-543	predetermined	_	_	
3-48	544-551	flicker	_	_	
3-49	552-556	rate	_	_	
3-50	557-559	or	_	_	
3-51	560-565	rates	_	_	
3-52	566-567	(	_	_	
3-53	567-570	e.g	_	_	
3-54	570-571	.	_	_	
3-55	571-572	,	_	_	
3-56	573-575	30	_	_	
3-57	575-576	,	_	_	
3-58	577-579	60	_	_	
3-59	579-580	,	_	_	
3-60	581-584	and	_	_	
3-61	584-585	/	_	_	
3-62	585-587	or	_	_	
3-63	588-591	180	_	_	
3-64	592-594	Hz	_	_	
3-65	594-595	)	_	_	
3-66	596-600	with	_	_	
3-67	601-604	the	_	_	
3-68	605-610	image	_	_	
3-69	611-614	for	_	_	
3-70	615-618	the	_	_	
3-71	619-623	left	_	_	
3-72	624-627	eye	_	_	
3-73	628-633	being	_	_	
3-74	634-641	present	_	_	
3-75	642-646	when	_	_	
3-76	647-650	the	_	_	
3-77	651-656	image	_	_	
3-78	657-660	for	_	_	
3-79	661-664	the	_	_	
3-80	665-670	right	_	_	
3-81	671-674	eye	_	_	
3-82	675-677	is	_	_	
3-83	678-681	not	_	_	
3-84	682-685	and	_	_	
3-85	686-690	vice	_	_	
3-86	691-696	versa	_	_	
3-87	696-697	.	_	_	

#Text=In some embodiments, a virtual image is shown only to the person's dominant eye and in others a virtual image is shown only to the person's non-dominant eye.
4-1	698-700	In	_	_	
4-2	701-705	some	_	_	
4-3	706-717	embodiments	_	_	
4-4	717-718	,	_	_	
4-5	719-720	a	_	_	
4-6	721-728	virtual	_	_	
4-7	729-734	image	_	_	
4-8	735-737	is	_	_	
4-9	738-743	shown	_	_	
4-10	744-748	only	_	_	
4-11	749-751	to	_	_	
4-12	752-755	the	_	_	
4-13	756-764	person's	_	_	
4-14	765-773	dominant	_	_	
4-15	774-777	eye	_	_	
4-16	778-781	and	_	_	
4-17	782-784	in	_	_	
4-18	785-791	others	_	_	
4-19	792-793	a	_	_	
4-20	794-801	virtual	_	_	
4-21	802-807	image	_	_	
4-22	808-810	is	_	_	
4-23	811-816	shown	_	_	
4-24	817-821	only	_	_	
4-25	822-824	to	_	_	
4-26	825-828	the	_	_	
4-27	829-837	person's	_	_	
4-28	838-850	non-dominant	_	_	
4-29	851-854	eye	_	_	
4-30	854-855	.	_	_	

#Text=In some embodiments which employ images which are interlaced in time, virtual images of various objects which are located at various distances from the user are displayed in the manner described above; when the user looks from the real image of one object to the real image of another object, only the virtual image corresponding to the real image of the object being viewed will be seen by the user's brain.
#Text=[0910] In embodiments, the invention provides methods for providing a depth cue with augmented reality virtual objects or virtual information that can convey a wide range of perceived depth to a broad range of individuals with different eye characteristics.
5-1	856-858	In	_	_	
5-2	859-863	some	_	_	
5-3	864-875	embodiments	_	_	
5-4	876-881	which	_	_	
5-5	882-888	employ	_	_	
5-6	889-895	images	_	_	
5-7	896-901	which	_	_	
5-8	902-905	are	_	_	
5-9	906-916	interlaced	_	_	
5-10	917-919	in	_	_	
5-11	920-924	time	_	_	
5-12	924-925	,	_	_	
5-13	926-933	virtual	_	_	
5-14	934-940	images	_	_	
5-15	941-943	of	_	_	
5-16	944-951	various	_	_	
5-17	952-959	objects	_	_	
5-18	960-965	which	_	_	
5-19	966-969	are	_	_	
5-20	970-977	located	_	_	
5-21	978-980	at	_	_	
5-22	981-988	various	_	_	
5-23	989-998	distances	_	_	
5-24	999-1003	from	_	_	
5-25	1004-1007	the	_	_	
5-26	1008-1012	user	_	_	
5-27	1013-1016	are	_	_	
5-28	1017-1026	displayed	_	_	
5-29	1027-1029	in	_	_	
5-30	1030-1033	the	_	_	
5-31	1034-1040	manner	_	_	
5-32	1041-1050	described	_	_	
5-33	1051-1056	above	_	_	
5-34	1056-1057	;	_	_	
5-35	1058-1062	when	_	_	
5-36	1063-1066	the	_	_	
5-37	1067-1071	user	_	_	
5-38	1072-1077	looks	_	_	
5-39	1078-1082	from	_	_	
5-40	1083-1086	the	_	_	
5-41	1087-1091	real	_	_	
5-42	1092-1097	image	_	_	
5-43	1098-1100	of	_	_	
5-44	1101-1104	one	_	_	
5-45	1105-1111	object	_	_	
5-46	1112-1114	to	_	_	
5-47	1115-1118	the	_	_	
5-48	1119-1123	real	_	_	
5-49	1124-1129	image	_	_	
5-50	1130-1132	of	_	_	
5-51	1133-1140	another	_	_	
5-52	1141-1147	object	_	_	
5-53	1147-1148	,	_	_	
5-54	1149-1153	only	_	_	
5-55	1154-1157	the	_	_	
5-56	1158-1165	virtual	_	_	
5-57	1166-1171	image	_	_	
5-58	1172-1185	corresponding	_	_	
5-59	1186-1188	to	_	_	
5-60	1189-1192	the	_	_	
5-61	1193-1197	real	_	_	
5-62	1198-1203	image	_	_	
5-63	1204-1206	of	_	_	
5-64	1207-1210	the	_	_	
5-65	1211-1217	object	_	_	
5-66	1218-1223	being	_	_	
5-67	1224-1230	viewed	_	_	
5-68	1231-1235	will	_	_	
5-69	1236-1238	be	_	_	
5-70	1239-1243	seen	_	_	
5-71	1244-1246	by	_	_	
5-72	1247-1250	the	_	_	
5-73	1251-1257	user's	_	_	
5-74	1258-1263	brain	_	_	
5-75	1263-1264	.	_	_	
5-76	1265-1266	[	_	_	
5-77	1266-1270	0910	_	_	
5-78	1270-1271	]	_	_	
5-79	1272-1274	In	_	_	
5-80	1275-1286	embodiments	_	_	
5-81	1286-1287	,	_	_	
5-82	1288-1291	the	_	_	
5-83	1292-1301	invention	_	_	
5-84	1302-1310	provides	_	_	
5-85	1311-1318	methods	_	_	
5-86	1319-1322	for	_	_	
5-87	1323-1332	providing	_	_	
5-88	1333-1334	a	_	_	
5-89	1335-1340	depth	_	_	
5-90	1341-1344	cue	_	_	
5-91	1345-1349	with	_	_	
5-92	1350-1359	augmented	_	_	
5-93	1360-1367	reality	_	_	
5-94	1368-1375	virtual	_	_	
5-95	1376-1383	objects	_	_	
5-96	1384-1386	or	_	_	
5-97	1387-1394	virtual	_	_	
5-98	1395-1406	information	_	_	
5-99	1407-1411	that	_	_	
5-100	1412-1415	can	_	_	
5-101	1416-1422	convey	_	_	
5-102	1423-1424	a	_	_	
5-103	1425-1429	wide	_	_	
5-104	1430-1435	range	_	_	
5-105	1436-1438	of	_	_	
5-106	1439-1448	perceived	_	_	
5-107	1449-1454	depth	_	_	
5-108	1455-1457	to	_	_	
5-109	1458-1459	a	_	_	
5-110	1460-1465	broad	_	_	
5-111	1466-1471	range	_	_	
5-112	1472-1474	of	_	_	
5-113	1475-1486	individuals	_	_	
5-114	1487-1491	with	_	_	
5-115	1492-1501	different	_	_	
5-116	1502-1505	eye	_	_	
5-117	1506-1521	characteristics	_	_	
5-118	1521-1522	.	_	_	

#Text=These depth cue method embodiments of the present invention use differences in the lateral positioning or disparity of the augmented reality images provided to the two eyes of the individual to provide differences in the vergence of the virtual objects or virtual information that convey a sense of depth.
6-1	1523-1528	These	_	_	
6-2	1529-1534	depth	_	_	
6-3	1535-1538	cue	_	_	
6-4	1539-1545	method	_	_	
6-5	1546-1557	embodiments	_	_	
6-6	1558-1560	of	_	_	
6-7	1561-1564	the	_	_	
6-8	1565-1572	present	_	_	
6-9	1573-1582	invention	_	_	
6-10	1583-1586	use	_	_	
6-11	1587-1598	differences	_	_	
6-12	1599-1601	in	_	_	
6-13	1602-1605	the	_	_	
6-14	1606-1613	lateral	_	_	
6-15	1614-1625	positioning	_	_	
6-16	1626-1628	or	_	_	
6-17	1629-1638	disparity	_	_	
6-18	1639-1641	of	_	_	
6-19	1642-1645	the	_	_	
6-20	1646-1655	augmented	_	_	
6-21	1656-1663	reality	_	_	
6-22	1664-1670	images	_	_	
6-23	1671-1679	provided	_	_	
6-24	1680-1682	to	_	_	
6-25	1683-1686	the	_	_	
6-26	1687-1690	two	_	_	
6-27	1691-1695	eyes	_	_	
6-28	1696-1698	of	_	_	
6-29	1699-1702	the	_	_	
6-30	1703-1713	individual	_	_	
6-31	1714-1716	to	_	_	
6-32	1717-1724	provide	_	_	
6-33	1725-1736	differences	_	_	
6-34	1737-1739	in	_	_	
6-35	1740-1743	the	_	_	
6-36	1744-1752	vergence	_	_	
6-37	1753-1755	of	_	_	
6-38	1756-1759	the	_	_	
6-39	1760-1767	virtual	_	_	
6-40	1768-1775	objects	_	_	
6-41	1776-1778	or	_	_	
6-42	1779-1786	virtual	_	_	
6-43	1787-1798	information	_	_	
6-44	1799-1803	that	_	_	
6-45	1804-1810	convey	_	_	
6-46	1811-1812	a	_	_	
6-47	1813-1818	sense	_	_	
6-48	1819-1821	of	_	_	
6-49	1822-1827	depth	_	_	
6-50	1827-1828	.	_	_	

#Text=One advantage of these methods is that the lateral shifting of the augmented reality images can be different for different portions of the augmented reality images so that the perceived depth is different for those portions.
7-1	1829-1832	One	_	_	
7-2	1833-1842	advantage	_	_	
7-3	1843-1845	of	_	_	
7-4	1846-1851	these	_	_	
7-5	1852-1859	methods	_	_	
7-6	1860-1862	is	_	_	
7-7	1863-1867	that	_	_	
7-8	1868-1871	the	_	_	
7-9	1872-1879	lateral	_	_	
7-10	1880-1888	shifting	_	_	
7-11	1889-1891	of	_	_	
7-12	1892-1895	the	_	_	
7-13	1896-1905	augmented	_	_	
7-14	1906-1913	reality	_	_	
7-15	1914-1920	images	_	_	
7-16	1921-1924	can	_	_	
7-17	1925-1927	be	_	_	
7-18	1928-1937	different	_	_	
7-19	1938-1941	for	_	_	
7-20	1942-1951	different	_	_	
7-21	1952-1960	portions	_	_	
7-22	1961-1963	of	_	_	
7-23	1964-1967	the	_	_	
7-24	1968-1977	augmented	_	_	
7-25	1978-1985	reality	_	_	
7-26	1986-1992	images	_	_	
7-27	1993-1995	so	_	_	
7-28	1996-2000	that	_	_	
7-29	2001-2004	the	_	_	
7-30	2005-2014	perceived	_	_	
7-31	2015-2020	depth	_	_	
7-32	2021-2023	is	_	_	
7-33	2024-2033	different	_	_	
7-34	2034-2037	for	_	_	
7-35	2038-2043	those	_	_	
7-36	2044-2052	portions	_	_	
7-37	2052-2053	.	_	_	

#Text=In addition, the lateral shifting can be done through image processing of the portions of the augmented reality images.
8-1	2054-2056	In	_	_	
8-2	2057-2065	addition	_	_	
8-3	2065-2066	,	_	_	
8-4	2067-2070	the	_	_	
8-5	2071-2078	lateral	_	_	
8-6	2079-2087	shifting	_	_	
8-7	2088-2091	can	_	_	
8-8	2092-2094	be	_	_	
8-9	2095-2099	done	_	_	
8-10	2100-2107	through	_	_	
8-11	2108-2113	image	_	_	
8-12	2114-2124	processing	_	_	
8-13	2125-2127	of	_	_	
8-14	2128-2131	the	_	_	
8-15	2132-2140	portions	_	_	
8-16	2141-2143	of	_	_	
8-17	2144-2147	the	_	_	
8-18	2148-2157	augmented	_	_	
8-19	2158-2165	reality	_	_	
8-20	2166-2172	images	_	_	
8-21	2172-2173	.	_	_	

#Text=The user can experience a full range of perceived depth through this method from as near as the individual can focus to infinity regardless of the individual's age.
#Text=[0911] In order to better understand these depth cue method embodiments of the present invention, it is useful to keep in mind that in some aspects of augmented reality, head mounted displays are used to add images of virtual objects or virtual information that are associated with the view of a scene as seen by a user.
9-1	2174-2177	The	_	_	
9-2	2178-2182	user	_	_	
9-3	2183-2186	can	_	_	
9-4	2187-2197	experience	_	_	
9-5	2198-2199	a	_	_	
9-6	2200-2204	full	_	_	
9-7	2205-2210	range	_	_	
9-8	2211-2213	of	_	_	
9-9	2214-2223	perceived	_	_	
9-10	2224-2229	depth	_	_	
9-11	2230-2237	through	_	_	
9-12	2238-2242	this	_	_	
9-13	2243-2249	method	_	_	
9-14	2250-2254	from	_	_	
9-15	2255-2257	as	_	_	
9-16	2258-2262	near	_	_	
9-17	2263-2265	as	_	_	
9-18	2266-2269	the	_	_	
9-19	2270-2280	individual	_	_	
9-20	2281-2284	can	_	_	
9-21	2285-2290	focus	_	_	
9-22	2291-2293	to	_	_	
9-23	2294-2302	infinity	_	_	
9-24	2303-2313	regardless	_	_	
9-25	2314-2316	of	_	_	
9-26	2317-2320	the	_	_	
9-27	2321-2333	individual's	_	_	
9-28	2334-2337	age	_	_	
9-29	2337-2338	.	_	_	
9-30	2339-2340	[	_	_	
9-31	2340-2344	0911	_	_	
9-32	2344-2345	]	_	_	
9-33	2346-2348	In	_	_	
9-34	2349-2354	order	_	_	
9-35	2355-2357	to	_	_	
9-36	2358-2364	better	_	_	
9-37	2365-2375	understand	_	_	
9-38	2376-2381	these	_	_	
9-39	2382-2387	depth	_	_	
9-40	2388-2391	cue	_	_	
9-41	2392-2398	method	_	_	
9-42	2399-2410	embodiments	_	_	
9-43	2411-2413	of	_	_	
9-44	2414-2417	the	_	_	
9-45	2418-2425	present	_	_	
9-46	2426-2435	invention	_	_	
9-47	2435-2436	,	_	_	
9-48	2437-2439	it	_	_	
9-49	2440-2442	is	_	_	
9-50	2443-2449	useful	_	_	
9-51	2450-2452	to	_	_	
9-52	2453-2457	keep	_	_	
9-53	2458-2460	in	_	_	
9-54	2461-2465	mind	_	_	
9-55	2466-2470	that	_	_	
9-56	2471-2473	in	_	_	
9-57	2474-2478	some	_	_	
9-58	2479-2486	aspects	_	_	
9-59	2487-2489	of	_	_	
9-60	2490-2499	augmented	_	_	
9-61	2500-2507	reality	_	_	
9-62	2507-2508	,	_	_	
9-63	2509-2513	head	_	_	
9-64	2514-2521	mounted	_	_	
9-65	2522-2530	displays	_	_	
9-66	2531-2534	are	_	_	
9-67	2535-2539	used	_	_	
9-68	2540-2542	to	_	_	
9-69	2543-2546	add	_	_	
9-70	2547-2553	images	_	_	
9-71	2554-2556	of	_	_	
9-72	2557-2564	virtual	_	_	
9-73	2565-2572	objects	_	_	
9-74	2573-2575	or	_	_	
9-75	2576-2583	virtual	_	_	
9-76	2584-2595	information	_	_	
9-77	2596-2600	that	_	_	
9-78	2601-2604	are	_	_	
9-79	2605-2615	associated	_	_	
9-80	2616-2620	with	_	_	
9-81	2621-2624	the	_	_	
9-82	2625-2629	view	_	_	
9-83	2630-2632	of	_	_	
9-84	2633-2634	a	_	_	
9-85	2635-2640	scene	_	_	
9-86	2641-2643	as	_	_	
9-87	2644-2648	seen	_	_	
9-88	2649-2651	by	_	_	
9-89	2652-2653	a	_	_	
9-90	2654-2658	user	_	_	
9-91	2658-2659	.	_	_	

#Text=To add additional effects to the perception of the augmented it is useful to place the virtual objects or virtual information at a perceived depth in the scene.
10-1	2660-2662	To	_	_	
10-2	2663-2666	add	_	_	
10-3	2667-2677	additional	_	_	
10-4	2678-2685	effects	_	_	
10-5	2686-2688	to	_	_	
10-6	2689-2692	the	_	_	
10-7	2693-2703	perception	_	_	
10-8	2704-2706	of	_	_	
10-9	2707-2710	the	_	_	
10-10	2711-2720	augmented	_	_	
10-11	2721-2723	it	_	_	
10-12	2724-2726	is	_	_	
10-13	2727-2733	useful	_	_	
10-14	2734-2736	to	_	_	
10-15	2737-2742	place	_	_	
10-16	2743-2746	the	_	_	
10-17	2747-2754	virtual	_	_	
10-18	2755-2762	objects	_	_	
10-19	2763-2765	or	_	_	
10-20	2766-2773	virtual	_	_	
10-21	2774-2785	information	_	_	
10-22	2786-2788	at	_	_	
10-23	2789-2790	a	_	_	
10-24	2791-2800	perceived	_	_	
10-25	2801-2806	depth	_	_	
10-26	2807-2809	in	_	_	
10-27	2810-2813	the	_	_	
10-28	2814-2819	scene	_	_	
10-29	2819-2820	.	_	_	

#Text=As an example, a virtual label can be placed onto an object in a scene such as the name of a building.
11-1	2821-2823	As	_	_	
11-2	2824-2826	an	_	_	
11-3	2827-2834	example	_	_	
11-4	2834-2835	,	_	_	
11-5	2836-2837	a	_	_	
11-6	2838-2845	virtual	_	_	
11-7	2846-2851	label	_	_	
11-8	2852-2855	can	_	_	
11-9	2856-2858	be	_	_	
11-10	2859-2865	placed	_	_	
11-11	2866-2870	onto	_	_	
11-12	2871-2873	an	_	_	
11-13	2874-2880	object	_	_	
11-14	2881-2883	in	_	_	
11-15	2884-2885	a	_	_	
11-16	2886-2891	scene	_	_	
11-17	2892-2896	such	_	_	
11-18	2897-2899	as	_	_	
11-19	2900-2903	the	_	_	
11-20	2904-2908	name	_	_	
11-21	2909-2911	of	_	_	
11-22	2912-2913	a	_	_	
11-23	2914-2922	building	_	_	
11-24	2922-2923	.	_	_	

#Text=The perceived association of the virtual label with the building is enhanced if the label and the building are perceived by the user to be at the same depth in the scene.
12-1	2924-2927	The	_	_	
12-2	2928-2937	perceived	_	_	
12-3	2938-2949	association	_	_	
12-4	2950-2952	of	_	_	
12-5	2953-2956	the	_	_	
12-6	2957-2964	virtual	_	_	
12-7	2965-2970	label	_	_	
12-8	2971-2975	with	_	_	
12-9	2976-2979	the	_	_	
12-10	2980-2988	building	_	_	
12-11	2989-2991	is	_	_	
12-12	2992-3000	enhanced	_	_	
12-13	3001-3003	if	_	_	
12-14	3004-3007	the	_	_	
12-15	3008-3013	label	_	_	
12-16	3014-3017	and	_	_	
12-17	3018-3021	the	_	_	
12-18	3022-3030	building	_	_	
12-19	3031-3034	are	_	_	
12-20	3035-3044	perceived	_	_	
12-21	3045-3047	by	_	_	
12-22	3048-3051	the	_	_	
12-23	3052-3056	user	_	_	
12-24	3057-3059	to	_	_	
12-25	3060-3062	be	_	_	
12-26	3063-3065	at	_	_	
12-27	3066-3069	the	_	_	
12-28	3070-3074	same	_	_	
12-29	3075-3080	depth	_	_	
12-30	3081-3083	in	_	_	
12-31	3084-3087	the	_	_	
12-32	3088-3093	scene	_	_	
12-33	3093-3094	.	_	_	

#Text=Head mounted displays with see-through capabilities are well suited to providing augmented reality information such as labels and objects because they provide the user with a clear view of the environment.
13-1	3095-3099	Head	_	_	
13-2	3100-3107	mounted	_	_	
13-3	3108-3116	displays	_	_	
13-4	3117-3121	with	_	_	
13-5	3122-3133	see-through	_	_	
13-6	3134-3146	capabilities	_	_	
13-7	3147-3150	are	_	_	
13-8	3151-3155	well	_	_	
13-9	3156-3162	suited	_	_	
13-10	3163-3165	to	_	_	
13-11	3166-3175	providing	_	_	
13-12	3176-3185	augmented	_	_	
13-13	3186-3193	reality	_	_	
13-14	3194-3205	information	_	_	
13-15	3206-3210	such	_	_	
13-16	3211-3213	as	_	_	
13-17	3214-3220	labels	_	_	
13-18	3221-3224	and	_	_	
13-19	3225-3232	objects	_	_	
13-20	3233-3240	because	_	_	
13-21	3241-3245	they	_	_	
13-22	3246-3253	provide	_	_	
13-23	3254-3257	the	_	_	
13-24	3258-3262	user	_	_	
13-25	3263-3267	with	_	_	
13-26	3268-3269	a	_	_	
13-27	3270-3275	clear	_	_	
13-28	3276-3280	view	_	_	
13-29	3281-3283	of	_	_	
13-30	3284-3287	the	_	_	
13-31	3288-3299	environment	_	_	
13-32	3299-3300	.	_	_	

#Text=However, for the augmented reality information to be of value, it must be easily associated with the objects in the environment and as such the positioning of the augmented reality information relative to the objects in the see-through view is important.
14-1	3301-3308	However	_	_	
14-2	3308-3309	,	_	_	
14-3	3310-3313	for	_	_	
14-4	3314-3317	the	_	_	
14-5	3318-3327	augmented	_	_	
14-6	3328-3335	reality	_	_	
14-7	3336-3347	information	_	_	
14-8	3348-3350	to	_	_	
14-9	3351-3353	be	_	_	
14-10	3354-3356	of	_	_	
14-11	3357-3362	value	_	_	
14-12	3362-3363	,	_	_	
14-13	3364-3366	it	_	_	
14-14	3367-3371	must	_	_	
14-15	3372-3374	be	_	_	
14-16	3375-3381	easily	_	_	
14-17	3382-3392	associated	_	_	
14-18	3393-3397	with	_	_	
14-19	3398-3401	the	_	_	
14-20	3402-3409	objects	_	_	
14-21	3410-3412	in	_	_	
14-22	3413-3416	the	_	_	
14-23	3417-3428	environment	_	_	
14-24	3429-3432	and	_	_	
14-25	3433-3435	as	_	_	
14-26	3436-3440	such	_	_	
14-27	3441-3444	the	_	_	
14-28	3445-3456	positioning	_	_	
14-29	3457-3459	of	_	_	
14-30	3460-3463	the	_	_	
14-31	3464-3473	augmented	_	_	
14-32	3474-3481	reality	_	_	
14-33	3482-3493	information	_	_	
14-34	3494-3502	relative	_	_	
14-35	3503-3505	to	_	_	
14-36	3506-3509	the	_	_	
14-37	3510-3517	objects	_	_	
14-38	3518-3520	in	_	_	
14-39	3521-3524	the	_	_	
14-40	3525-3536	see-through	_	_	
14-41	3537-3541	view	_	_	
14-42	3542-3544	is	_	_	
14-43	3545-3554	important	_	_	
14-44	3554-3555	.	_	_	

#Text=While horizontal and vertical positioning of augmented reality information is relatively straight forward if the head mounted display has a camera that can be calibrated to the see-through view, the depth positioning is more complicated.
15-1	3556-3561	While	_	_	
15-2	3562-3572	horizontal	_	_	
15-3	3573-3576	and	_	_	
15-4	3577-3585	vertical	_	_	
15-5	3586-3597	positioning	_	_	
15-6	3598-3600	of	_	_	
15-7	3601-3610	augmented	_	_	
15-8	3611-3618	reality	_	_	
15-9	3619-3630	information	_	_	
15-10	3631-3633	is	_	_	
15-11	3634-3644	relatively	_	_	
15-12	3645-3653	straight	_	_	
15-13	3654-3661	forward	_	_	
15-14	3662-3664	if	_	_	
15-15	3665-3668	the	_	_	
15-16	3669-3673	head	_	_	
15-17	3674-3681	mounted	_	_	
15-18	3682-3689	display	_	_	
15-19	3690-3693	has	_	_	
15-20	3694-3695	a	_	_	
15-21	3696-3702	camera	_	_	
15-22	3703-3707	that	_	_	
15-23	3708-3711	can	_	_	
15-24	3712-3714	be	_	_	
15-25	3715-3725	calibrated	_	_	
15-26	3726-3728	to	_	_	
15-27	3729-3732	the	_	_	
15-28	3733-3744	see-through	_	_	
15-29	3745-3749	view	_	_	
15-30	3749-3750	,	_	_	
15-31	3751-3754	the	_	_	
15-32	3755-3760	depth	_	_	
15-33	3761-3772	positioning	_	_	
15-34	3773-3775	is	_	_	
15-35	3776-3780	more	_	_	
15-36	3781-3792	complicated	_	_	
15-37	3792-3793	.	_	_	

#Text=U.S.
16-1	3794-3797	U.S	_	_	
16-2	3797-3798	.	_	_	

#Text=Pat.
17-1	3799-3802	Pat	_	_	
17-2	3802-3803	.	_	_	

#Text=No. 6,690,393 describes a method for positioning 2D labels in a 3D virtual world.
18-1	3804-3806	No	_	_	
18-2	3806-3807	.	_	_	
18-3	3808-3817	6,690,393	_	_	
18-4	3818-3827	describes	_	_	
18-5	3828-3829	a	*[1]	19-3[2_1]	
18-6	3830-3836	method	*[1]	_	
18-7	3837-3840	for	*[1]	_	
18-8	3841-3852	positioning	*[1]	_	
18-9	3853-3855	2D	*[1]	_	
18-10	3856-3862	labels	*[1]	_	
18-11	3863-3865	in	*[1]	_	
18-12	3866-3867	a	*[1]	_	
18-13	3868-3870	3D	*[1]	_	
18-14	3871-3878	virtual	*[1]	_	
18-15	3879-3884	world	*[1]	_	
18-16	3884-3885	.	_	_	

#Text=However, this method is not directed at displays with a see-through view where the majority of the image the user sees is not provided digitally and as such the 3D location of objects is not known.
19-1	3886-3893	However	_	_	
19-2	3893-3894	,	_	_	
19-3	3895-3899	this	*[2]	_	
19-4	3900-3906	method	*[2]	_	
19-5	3907-3909	is	_	_	
19-6	3910-3913	not	_	_	
19-7	3914-3922	directed	_	_	
19-8	3923-3925	at	_	_	
19-9	3926-3934	displays	_	_	
19-10	3935-3939	with	_	_	
19-11	3940-3941	a	_	_	
19-12	3942-3953	see-through	_	_	
19-13	3954-3958	view	_	_	
19-14	3959-3964	where	_	_	
19-15	3965-3968	the	_	_	
19-16	3969-3977	majority	_	_	
19-17	3978-3980	of	_	_	
19-18	3981-3984	the	_	_	
19-19	3985-3990	image	_	_	
19-20	3991-3994	the	_	_	
19-21	3995-3999	user	_	_	
19-22	4000-4004	sees	_	_	
19-23	4005-4007	is	_	_	
19-24	4008-4011	not	_	_	
19-25	4012-4020	provided	_	_	
19-26	4021-4030	digitally	_	_	
19-27	4031-4034	and	_	_	
19-28	4035-4037	as	_	_	
19-29	4038-4042	such	_	_	
19-30	4043-4046	the	_	_	
19-31	4047-4049	3D	_	_	
19-32	4050-4058	location	_	_	
19-33	4059-4061	of	_	_	
19-34	4062-4069	objects	_	_	
19-35	4070-4072	is	_	_	
19-36	4073-4076	not	_	_	
19-37	4077-4082	known	_	_	
19-38	4082-4083	.	_	_	

#Text=U.S.
20-1	4084-4087	U.S	_	_	
20-2	4087-4088	.	_	_	

#Text=Pat.
21-1	4089-4092	Pat	_	_	
21-2	4092-4093	.	_	_	

#Text=No. 7,907,166 describes a robotic surgical system using a stereo viewer in which telestration graphics are overlaid onto stereo images of an operating site.
22-1	4094-4096	No	_	_	
22-2	4096-4097	.	_	_	
22-3	4098-4107	7,907,166	_	_	
22-4	4108-4117	describes	_	_	
22-5	4118-4119	a	_	_	
22-6	4120-4127	robotic	_	_	
22-7	4128-4136	surgical	_	_	
22-8	4137-4143	system	_	_	
22-9	4144-4149	using	_	_	
22-10	4150-4151	a	_	_	
22-11	4152-4158	stereo	_	_	
22-12	4159-4165	viewer	_	_	
22-13	4166-4168	in	_	_	
22-14	4169-4174	which	_	_	
22-15	4175-4187	telestration	_	_	
22-16	4188-4196	graphics	_	_	
22-17	4197-4200	are	_	_	
22-18	4201-4209	overlaid	_	_	
22-19	4210-4214	onto	_	_	
22-20	4215-4221	stereo	_	_	
22-21	4222-4228	images	_	_	
22-22	4229-4231	of	_	_	
22-23	4232-4234	an	_	_	
22-24	4235-4244	operating	_	_	
22-25	4245-4249	site	_	_	
22-26	4249-4250	.	_	_	

#Text=However, similar to the method described in U.S.
23-1	4251-4258	However	_	_	
23-2	4258-4259	,	_	_	
23-3	4260-4267	similar	_	_	
23-4	4268-4270	to	_	_	
23-5	4271-4274	the	_	_	
23-6	4275-4281	method	_	_	
23-7	4282-4291	described	_	_	
23-8	4292-4294	in	_	_	
23-9	4295-4298	U.S	_	_	
23-10	4298-4299	.	_	_	

#Text=Pat.
24-1	4300-4303	Pat	_	_	
24-2	4303-4304	.	_	_	

#Text=No. 6,690,393, this system uses captured images which are then manipulated to add graphics and as such does not address the unique situation with see-through displays wherein the majority of the image is not provided digitally and the relative locations of objects that the user sees are not known.
25-1	4305-4307	No	_	_	
25-2	4307-4308	.	_	_	
25-3	4309-4318	6,690,393	_	_	
25-4	4318-4319	,	_	_	
25-5	4320-4324	this	_	_	
25-6	4325-4331	system	_	_	
25-7	4332-4336	uses	_	_	
25-8	4337-4345	captured	_	_	
25-9	4346-4352	images	_	_	
25-10	4353-4358	which	_	_	
25-11	4359-4362	are	_	_	
25-12	4363-4367	then	_	_	
25-13	4368-4379	manipulated	_	_	
25-14	4380-4382	to	_	_	
25-15	4383-4386	add	_	_	
25-16	4387-4395	graphics	_	_	
25-17	4396-4399	and	_	_	
25-18	4400-4402	as	_	_	
25-19	4403-4407	such	_	_	
25-20	4408-4412	does	_	_	
25-21	4413-4416	not	_	_	
25-22	4417-4424	address	_	_	
25-23	4425-4428	the	_	_	
25-24	4429-4435	unique	_	_	
25-25	4436-4445	situation	_	_	
25-26	4446-4450	with	_	_	
25-27	4451-4462	see-through	_	_	
25-28	4463-4471	displays	_	_	
25-29	4472-4479	wherein	_	_	
25-30	4480-4483	the	_	_	
25-31	4484-4492	majority	_	_	
25-32	4493-4495	of	_	_	
25-33	4496-4499	the	_	_	
25-34	4500-4505	image	_	_	
25-35	4506-4508	is	_	_	
25-36	4509-4512	not	_	_	
25-37	4513-4521	provided	_	_	
25-38	4522-4531	digitally	_	_	
25-39	4532-4535	and	_	_	
25-40	4536-4539	the	_	_	
25-41	4540-4548	relative	_	_	
25-42	4549-4558	locations	_	_	
25-43	4559-4561	of	_	_	
25-44	4562-4569	objects	_	_	
25-45	4570-4574	that	_	_	
25-46	4575-4578	the	_	_	
25-47	4579-4583	user	_	_	
25-48	4584-4588	sees	_	_	
25-49	4589-4592	are	_	_	
25-50	4593-4596	not	_	_	
25-51	4597-4602	known	_	_	
25-52	4602-4603	.	_	_	

#Text=Another prior art method for augmented reality is to adjust the focus of the virtual objects or virtual information so that the user perceives differences in focus depth that provide a depth cue to the user.
26-1	4604-4611	Another	_	_	
26-2	4612-4617	prior	_	_	
26-3	4618-4621	art	_	_	
26-4	4622-4628	method	_	_	
26-5	4629-4632	for	_	_	
26-6	4633-4642	augmented	_	_	
26-7	4643-4650	reality	_	_	
26-8	4651-4653	is	_	_	
26-9	4654-4656	to	_	_	
26-10	4657-4663	adjust	_	_	
26-11	4664-4667	the	_	_	
26-12	4668-4673	focus	_	_	
26-13	4674-4676	of	_	_	
26-14	4677-4680	the	_	_	
26-15	4681-4688	virtual	_	_	
26-16	4689-4696	objects	_	_	
26-17	4697-4699	or	_	_	
26-18	4700-4707	virtual	_	_	
26-19	4708-4719	information	_	_	
26-20	4720-4722	so	_	_	
26-21	4723-4727	that	_	_	
26-22	4728-4731	the	_	_	
26-23	4732-4736	user	_	_	
26-24	4737-4746	perceives	_	_	
26-25	4747-4758	differences	_	_	
26-26	4759-4761	in	_	_	
26-27	4762-4767	focus	_	_	
26-28	4768-4773	depth	_	_	
26-29	4774-4778	that	_	_	
26-30	4779-4786	provide	_	_	
26-31	4787-4788	a	_	_	
26-32	4789-4794	depth	_	_	
26-33	4795-4798	cue	_	_	
26-34	4799-4801	to	_	_	
26-35	4802-4805	the	_	_	
26-36	4806-4810	user	_	_	
26-37	4810-4811	.	_	_	

#Text=As the user has to refocus his/her eyes to look at objects in the scene and to look at the virtual objects or virtual information, the user perceives an associated depth.
27-1	4812-4814	As	_	_	
27-2	4815-4818	the	_	_	
27-3	4819-4823	user	_	_	
27-4	4824-4827	has	_	_	
27-5	4828-4830	to	_	_	
27-6	4831-4838	refocus	_	_	
27-7	4839-4842	his	_	_	
27-8	4842-4843	/	_	_	
27-9	4843-4846	her	_	_	
27-10	4847-4851	eyes	_	_	
27-11	4852-4854	to	_	_	
27-12	4855-4859	look	_	_	
27-13	4860-4862	at	_	_	
27-14	4863-4870	objects	_	_	
27-15	4871-4873	in	_	_	
27-16	4874-4877	the	_	_	
27-17	4878-4883	scene	_	_	
27-18	4884-4887	and	_	_	
27-19	4888-4890	to	_	_	
27-20	4891-4895	look	_	_	
27-21	4896-4898	at	_	_	
27-22	4899-4902	the	_	_	
27-23	4903-4910	virtual	_	_	
27-24	4911-4918	objects	_	_	
27-25	4919-4921	or	_	_	
27-26	4922-4929	virtual	_	_	
27-27	4930-4941	information	_	_	
27-28	4941-4942	,	_	_	
27-29	4943-4946	the	_	_	
27-30	4947-4951	user	_	_	
27-31	4952-4961	perceives	_	_	
27-32	4962-4964	an	_	_	
27-33	4965-4975	associated	_	_	
27-34	4976-4981	depth	_	_	
27-35	4981-4982	.	_	_	

#Text=However, the range of depth that can be associated with focus is limited by the accommodation that the user's eyes are capable of This accommodation can be limited in some individuals particularly if the individual is older when eyes lose much of their accommodation range.
28-1	4983-4990	However	_	_	
28-2	4990-4991	,	_	_	
28-3	4992-4995	the	_	_	
28-4	4996-5001	range	_	_	
28-5	5002-5004	of	_	_	
28-6	5005-5010	depth	_	_	
28-7	5011-5015	that	_	_	
28-8	5016-5019	can	_	_	
28-9	5020-5022	be	_	_	
28-10	5023-5033	associated	_	_	
28-11	5034-5038	with	_	_	
28-12	5039-5044	focus	_	_	
28-13	5045-5047	is	_	_	
28-14	5048-5055	limited	_	_	
28-15	5056-5058	by	_	_	
28-16	5059-5062	the	_	_	
28-17	5063-5076	accommodation	_	_	
28-18	5077-5081	that	_	_	
28-19	5082-5085	the	_	_	
28-20	5086-5092	user's	_	_	
28-21	5093-5097	eyes	_	_	
28-22	5098-5101	are	_	_	
28-23	5102-5109	capable	_	_	
28-24	5110-5112	of	_	_	
28-25	5113-5117	This	_	_	
28-26	5118-5131	accommodation	_	_	
28-27	5132-5135	can	_	_	
28-28	5136-5138	be	_	_	
28-29	5139-5146	limited	_	_	
28-30	5147-5149	in	_	_	
28-31	5150-5154	some	_	_	
28-32	5155-5166	individuals	_	_	
28-33	5167-5179	particularly	_	_	
28-34	5180-5182	if	_	_	
28-35	5183-5186	the	_	_	
28-36	5187-5197	individual	_	_	
28-37	5198-5200	is	_	_	
28-38	5201-5206	older	_	_	
28-39	5207-5211	when	_	_	
28-40	5212-5216	eyes	_	_	
28-41	5217-5221	lose	_	_	
28-42	5222-5226	much	_	_	
28-43	5227-5229	of	_	_	
28-44	5230-5235	their	_	_	
28-45	5236-5249	accommodation	_	_	
28-46	5250-5255	range	_	_	
28-47	5255-5256	.	_	_	

#Text=In addition, the accommodation range is different depending on whether the user is near sighted or far sighted.
29-1	5257-5259	In	_	_	
29-2	5260-5268	addition	_	_	
29-3	5268-5269	,	_	_	
29-4	5270-5273	the	_	_	
29-5	5274-5287	accommodation	_	_	
29-6	5288-5293	range	_	_	
29-7	5294-5296	is	_	_	
29-8	5297-5306	different	_	_	
29-9	5307-5316	depending	_	_	
29-10	5317-5319	on	_	_	
29-11	5320-5327	whether	_	_	
29-12	5328-5331	the	_	_	
29-13	5332-5336	user	_	_	
29-14	5337-5339	is	_	_	
29-15	5340-5344	near	_	_	
29-16	5345-5352	sighted	_	_	
29-17	5353-5355	or	_	_	
29-18	5356-5359	far	_	_	
29-19	5360-5367	sighted	_	_	
29-20	5367-5368	.	_	_	

#Text=These factors make the result of using focus cues unreliable for a large population of user's with different ages and different eye characteristics.
30-1	5369-5374	These	_	_	
30-2	5375-5382	factors	_	_	
30-3	5383-5387	make	_	_	
30-4	5388-5391	the	_	_	
30-5	5392-5398	result	_	_	
30-6	5399-5401	of	_	_	
30-7	5402-5407	using	_	_	
30-8	5408-5413	focus	_	_	
30-9	5414-5418	cues	_	_	
30-10	5419-5429	unreliable	_	_	
30-11	5430-5433	for	_	_	
30-12	5434-5435	a	_	_	
30-13	5436-5441	large	_	_	
30-14	5442-5452	population	_	_	
30-15	5453-5455	of	_	_	
30-16	5456-5462	user's	_	_	
30-17	5463-5467	with	_	_	
30-18	5468-5477	different	_	_	
30-19	5478-5482	ages	_	_	
30-20	5483-5486	and	_	_	
30-21	5487-5496	different	_	_	
30-22	5497-5500	eye	_	_	
30-23	5501-5516	characteristics	_	_	
30-24	5516-5517	.	_	_	

#Text=Therefore, the need persists beyond what is available in the prior art for a widely useable method for associating depth information with augmented reality.
#Text=[0912] Some of the depth cue method embodiments of the present invention are described in this and the following paragraphs [0XXX] through [0XYZ].
31-1	5518-5527	Therefore	_	_	
31-2	5527-5528	,	_	_	
31-3	5529-5532	the	_	_	
31-4	5533-5537	need	_	_	
31-5	5538-5546	persists	_	_	
31-6	5547-5553	beyond	_	_	
31-7	5554-5558	what	_	_	
31-8	5559-5561	is	_	_	
31-9	5562-5571	available	_	_	
31-10	5572-5574	in	_	_	
31-11	5575-5578	the	_	_	
31-12	5579-5584	prior	_	_	
31-13	5585-5588	art	_	_	
31-14	5589-5592	for	_	_	
31-15	5593-5594	a	_	_	
31-16	5595-5601	widely	_	_	
31-17	5602-5609	useable	_	_	
31-18	5610-5616	method	_	_	
31-19	5617-5620	for	_	_	
31-20	5621-5632	associating	_	_	
31-21	5633-5638	depth	_	_	
31-22	5639-5650	information	_	_	
31-23	5651-5655	with	_	_	
31-24	5656-5665	augmented	_	_	
31-25	5666-5673	reality	_	_	
31-26	5673-5674	.	_	_	
31-27	5675-5676	[	_	_	
31-28	5676-5680	0912	_	_	
31-29	5680-5681	]	_	_	
31-30	5682-5686	Some	_	_	
31-31	5687-5689	of	_	_	
31-32	5690-5693	the	_	_	
31-33	5694-5699	depth	_	_	
31-34	5700-5703	cue	_	_	
31-35	5704-5710	method	_	_	
31-36	5711-5722	embodiments	_	_	
31-37	5723-5725	of	_	_	
31-38	5726-5729	the	_	_	
31-39	5730-5737	present	_	_	
31-40	5738-5747	invention	_	_	
31-41	5748-5751	are	_	_	
31-42	5752-5761	described	_	_	
31-43	5762-5764	in	_	_	
31-44	5765-5769	this	_	_	
31-45	5770-5773	and	_	_	
31-46	5774-5777	the	_	_	
31-47	5778-5787	following	_	_	
31-48	5788-5798	paragraphs	_	_	
31-49	5799-5800	[	_	_	
31-50	5800-5804	0XXX	_	_	
31-51	5804-5805	]	_	_	
31-52	5806-5813	through	_	_	
31-53	5814-5815	[	_	_	
31-54	5815-5819	0XYZ	_	_	
31-55	5819-5820	]	_	_	
31-56	5820-5821	.	_	_	

#Text=Head mounted displays with see-through capabilities provide a clear view of the scene in front of the user while also providing the ability to display an image, where the user sees a combined image comprised of the see-through view with the display image overlaid.
32-1	5822-5826	Head	_	_	
32-2	5827-5834	mounted	_	_	
32-3	5835-5843	displays	_	_	
32-4	5844-5848	with	_	_	
32-5	5849-5860	see-through	_	_	
32-6	5861-5873	capabilities	_	_	
32-7	5874-5881	provide	_	_	
32-8	5882-5883	a	_	_	
32-9	5884-5889	clear	_	_	
32-10	5890-5894	view	_	_	
32-11	5895-5897	of	_	_	
32-12	5898-5901	the	_	_	
32-13	5902-5907	scene	_	_	
32-14	5908-5910	in	_	_	
32-15	5911-5916	front	_	_	
32-16	5917-5919	of	_	_	
32-17	5920-5923	the	_	_	
32-18	5924-5928	user	_	_	
32-19	5929-5934	while	_	_	
32-20	5935-5939	also	_	_	
32-21	5940-5949	providing	_	_	
32-22	5950-5953	the	_	_	
32-23	5954-5961	ability	_	_	
32-24	5962-5964	to	_	_	
32-25	5965-5972	display	_	_	
32-26	5973-5975	an	_	_	
32-27	5976-5981	image	_	_	
32-28	5981-5982	,	_	_	
32-29	5983-5988	where	_	_	
32-30	5989-5992	the	_	_	
32-31	5993-5997	user	_	_	
32-32	5998-6002	sees	_	_	
32-33	6003-6004	a	_	_	
32-34	6005-6013	combined	_	_	
32-35	6014-6019	image	_	_	
32-36	6020-6029	comprised	_	_	
32-37	6030-6032	of	_	_	
32-38	6033-6036	the	_	_	
32-39	6037-6048	see-through	_	_	
32-40	6049-6053	view	_	_	
32-41	6054-6058	with	_	_	
32-42	6059-6062	the	_	_	
32-43	6063-6070	display	_	_	
32-44	6071-6076	image	_	_	
32-45	6077-6085	overlaid	_	_	
32-46	6085-6086	.	_	_	

#Text=The methods are entail the displaying of 3D labels and other 3D information using the see-through display to aid the user in interpreting the environment surrounding the user.
33-1	6087-6090	The	_	_	
33-2	6091-6098	methods	_	_	
33-3	6099-6102	are	_	_	
33-4	6103-6109	entail	_	_	
33-5	6110-6113	the	_	_	
33-6	6114-6124	displaying	_	_	
33-7	6125-6127	of	_	_	
33-8	6128-6130	3D	_	_	
33-9	6131-6137	labels	_	_	
33-10	6138-6141	and	_	_	
33-11	6142-6147	other	_	_	
33-12	6148-6150	3D	_	_	
33-13	6151-6162	information	_	_	
33-14	6163-6168	using	_	_	
33-15	6169-6172	the	_	_	
33-16	6173-6184	see-through	_	_	
33-17	6185-6192	display	_	_	
33-18	6193-6195	to	_	_	
33-19	6196-6199	aid	_	_	
33-20	6200-6203	the	_	_	
33-21	6204-6208	user	_	_	
33-22	6209-6211	in	_	_	
33-23	6212-6224	interpreting	_	_	
33-24	6225-6228	the	_	_	
33-25	6229-6240	environment	_	_	
33-26	6241-6252	surrounding	_	_	
33-27	6253-6256	the	_	_	
33-28	6257-6261	user	_	_	
33-29	6261-6262	.	_	_	

#Text=A stereo pair of images of the 3D labels and other 3D information may be presented to the left and right eyes of the user to position the 3D labels and other 3D information at different depths in the scene as perceived by the user.
34-1	6263-6264	A	_	_	
34-2	6265-6271	stereo	_	_	
34-3	6272-6276	pair	_	_	
34-4	6277-6279	of	_	_	
34-5	6280-6286	images	_	_	
34-6	6287-6289	of	_	_	
34-7	6290-6293	the	_	_	
34-8	6294-6296	3D	_	_	
34-9	6297-6303	labels	_	_	
34-10	6304-6307	and	_	_	
34-11	6308-6313	other	_	_	
34-12	6314-6316	3D	_	_	
34-13	6317-6328	information	_	_	
34-14	6329-6332	may	_	_	
34-15	6333-6335	be	_	_	
34-16	6336-6345	presented	_	_	
34-17	6346-6348	to	_	_	
34-18	6349-6352	the	_	_	
34-19	6353-6357	left	_	_	
34-20	6358-6361	and	_	_	
34-21	6362-6367	right	_	_	
34-22	6368-6372	eyes	_	_	
34-23	6373-6375	of	_	_	
34-24	6376-6379	the	_	_	
34-25	6380-6384	user	_	_	
34-26	6385-6387	to	_	_	
34-27	6388-6396	position	_	_	
34-28	6397-6400	the	_	_	
34-29	6401-6403	3D	_	_	
34-30	6404-6410	labels	_	_	
34-31	6411-6414	and	_	_	
34-32	6415-6420	other	_	_	
34-33	6421-6423	3D	_	_	
34-34	6424-6435	information	_	_	
34-35	6436-6438	at	_	_	
34-36	6439-6448	different	_	_	
34-37	6449-6455	depths	_	_	
34-38	6456-6458	in	_	_	
34-39	6459-6462	the	_	_	
34-40	6463-6468	scene	_	_	
34-41	6469-6471	as	_	_	
34-42	6472-6481	perceived	_	_	
34-43	6482-6484	by	_	_	
34-44	6485-6488	the	_	_	
34-45	6489-6493	user	_	_	
34-46	6493-6494	.	_	_	

#Text=In this way the 3D labels and other 3D information can be more easily associated with the see-through view and the surrounding environment.
#Text=[0913] FIG. 109 is an illustration of a head mounted display device 109100 with see-through capabilities and is a special version of augmented reality eyepiece 100 shown in FIG. 1 and described throughout this document.
35-1	6495-6497	In	_	_	
35-2	6498-6502	this	_	_	
35-3	6503-6506	way	_	_	
35-4	6507-6510	the	_	_	
35-5	6511-6513	3D	_	_	
35-6	6514-6520	labels	_	_	
35-7	6521-6524	and	_	_	
35-8	6525-6530	other	_	_	
35-9	6531-6533	3D	_	_	
35-10	6534-6545	information	_	_	
35-11	6546-6549	can	_	_	
35-12	6550-6552	be	_	_	
35-13	6553-6557	more	_	_	
35-14	6558-6564	easily	_	_	
35-15	6565-6575	associated	_	_	
35-16	6576-6580	with	_	_	
35-17	6581-6584	the	_	_	
35-18	6585-6596	see-through	_	_	
35-19	6597-6601	view	_	_	
35-20	6602-6605	and	_	_	
35-21	6606-6609	the	_	_	
35-22	6610-6621	surrounding	_	_	
35-23	6622-6633	environment	_	_	
35-24	6633-6634	.	_	_	
35-25	6635-6636	[	_	_	
35-26	6636-6640	0913	_	_	
35-27	6640-6641	]	_	_	
35-28	6642-6645	FIG	_	_	
35-29	6645-6646	.	_	_	
35-30	6647-6650	109	_	_	
35-31	6651-6653	is	_	_	
35-32	6654-6656	an	_	_	
35-33	6657-6669	illustration	_	_	
35-34	6670-6672	of	_	_	
35-35	6673-6674	a	_	_	
35-36	6675-6679	head	_	_	
35-37	6680-6687	mounted	_	_	
35-38	6688-6695	display	_	_	
35-39	6696-6702	device	_	_	
35-40	6703-6709	109100	_	_	
35-41	6710-6714	with	_	_	
35-42	6715-6726	see-through	_	_	
35-43	6727-6739	capabilities	_	_	
35-44	6740-6743	and	_	_	
35-45	6744-6746	is	_	_	
35-46	6747-6748	a	_	_	
35-47	6749-6756	special	_	_	
35-48	6757-6764	version	_	_	
35-49	6765-6767	of	_	_	
35-50	6768-6777	augmented	_	_	
35-51	6778-6785	reality	_	_	
35-52	6786-6794	eyepiece	_	_	
35-53	6795-6798	100	_	_	
35-54	6799-6804	shown	_	_	
35-55	6805-6807	in	_	_	
35-56	6808-6811	FIG	_	_	
35-57	6811-6812	.	_	_	
35-58	6813-6814	1	_	_	
35-59	6815-6818	and	_	_	
35-60	6819-6828	described	_	_	
35-61	6829-6839	throughout	_	_	
35-62	6840-6844	this	_	_	
35-63	6845-6853	document	_	_	
35-64	6853-6854	.	_	_	

#Text=The head mounted display device 109100 includes see-through displays 109110, stereo cameras 109120, electronics 109130, and range finder 109140.
36-1	6855-6858	The	_	_	
36-2	6859-6863	head	_	_	
36-3	6864-6871	mounted	_	_	
36-4	6872-6879	display	_	_	
36-5	6880-6886	device	_	_	
36-6	6887-6893	109100	_	_	
36-7	6894-6902	includes	_	_	
36-8	6903-6914	see-through	_	_	
36-9	6915-6923	displays	_	_	
36-10	6924-6930	109110	_	_	
36-11	6930-6931	,	_	_	
36-12	6932-6938	stereo	_	_	
36-13	6939-6946	cameras	_	_	
36-14	6947-6953	109120	_	_	
36-15	6953-6954	,	_	_	
36-16	6955-6966	electronics	_	_	
36-17	6967-6973	109130	_	_	
36-18	6973-6974	,	_	_	
36-19	6975-6978	and	_	_	
36-20	6979-6984	range	_	_	
36-21	6985-6991	finder	_	_	
36-22	6992-6998	109140	_	_	
36-23	6998-6999	.	_	_	

#Text=This Wherein the electronics can include one or more of the following: a processor, a battery, a global positioning sensor (GPS), a direction sensor, data storage, a wireless communication system and a user interface.
37-1	7000-7004	This	_	_	
37-2	7005-7012	Wherein	_	_	
37-3	7013-7016	the	_	_	
37-4	7017-7028	electronics	_	_	
37-5	7029-7032	can	_	_	
37-6	7033-7040	include	_	_	
37-7	7041-7044	one	_	_	
37-8	7045-7047	or	_	_	
37-9	7048-7052	more	_	_	
37-10	7053-7055	of	_	_	
37-11	7056-7059	the	_	_	
37-12	7060-7069	following	_	_	
37-13	7069-7070	:	_	_	
37-14	7071-7072	a	_	_	
37-15	7073-7082	processor	_	_	
37-16	7082-7083	,	_	_	
37-17	7084-7085	a	_	_	
37-18	7086-7093	battery	_	_	
37-19	7093-7094	,	_	_	
37-20	7095-7096	a	_	_	
37-21	7097-7103	global	_	_	
37-22	7104-7115	positioning	_	_	
37-23	7116-7122	sensor	_	_	
37-24	7123-7124	(	_	_	
37-25	7124-7127	GPS	_	_	
37-26	7127-7128	)	_	_	
37-27	7128-7129	,	_	_	
37-28	7130-7131	a	_	_	
37-29	7132-7141	direction	_	_	
37-30	7142-7148	sensor	_	_	
37-31	7148-7149	,	_	_	
37-32	7150-7154	data	_	_	
37-33	7155-7162	storage	_	_	
37-34	7162-7163	,	_	_	
37-35	7164-7165	a	_	_	
37-36	7166-7174	wireless	_	_	
37-37	7175-7188	communication	_	_	
37-38	7189-7195	system	_	_	
37-39	7196-7199	and	_	_	
37-40	7200-7201	a	_	_	
37-41	7202-7206	user	_	_	
37-42	7207-7216	interface	_	_	
37-43	7216-7217	.	_	_	
