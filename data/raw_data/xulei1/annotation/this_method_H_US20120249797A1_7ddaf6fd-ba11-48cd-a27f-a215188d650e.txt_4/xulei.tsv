#FORMAT=WebAnno TSV 3.2
#T_SP=webanno.custom.Diy_coref|
#T_RL=webanno.custom.Diy_coref_re|BT_webanno.custom.Diy_coref


#Text=[0908] It is to be noted that some range finding devices use range determining methodologies in which information received from a device's sensors is mapped upon a space-representing rectilinear or non-rectilinear grid.
1-1	0-1	[	_	_	
1-2	1-5	0908	_	_	
1-3	5-6	]	_	_	
1-4	7-9	It	_	_	
1-5	10-12	is	_	_	
1-6	13-15	to	_	_	
1-7	16-18	be	_	_	
1-8	19-24	noted	_	_	
1-9	25-29	that	_	_	
1-10	30-34	some	_	_	
1-11	35-40	range	_	_	
1-12	41-48	finding	_	_	
1-13	49-56	devices	_	_	
1-14	57-60	use	_	_	
1-15	61-66	range	_	_	
1-16	67-78	determining	_	_	
1-17	79-92	methodologies	_	_	
1-18	93-95	in	_	_	
1-19	96-101	which	_	_	
1-20	102-113	information	_	_	
1-21	114-122	received	_	_	
1-22	123-127	from	_	_	
1-23	128-129	a	_	_	
1-24	130-138	device's	_	_	
1-25	139-146	sensors	_	_	
1-26	147-149	is	_	_	
1-27	150-156	mapped	_	_	
1-28	157-161	upon	_	_	
1-29	162-163	a	_	_	
1-30	164-182	space-representing	_	_	
1-31	183-194	rectilinear	_	_	
1-32	195-197	or	_	_	
1-33	198-213	non-rectilinear	_	_	
1-34	214-218	grid	_	_	
1-35	218-219	.	_	_	

#Text=The information from the various sectors of the grid is inter-compared to determine the range distance.
2-1	220-223	The	_	_	
2-2	224-235	information	_	_	
2-3	236-240	from	_	_	
2-4	241-244	the	_	_	
2-5	245-252	various	_	_	
2-6	253-260	sectors	_	_	
2-7	261-263	of	_	_	
2-8	264-267	the	_	_	
2-9	268-272	grid	_	_	
2-10	273-275	is	_	_	
2-11	276-290	inter-compared	_	_	
2-12	291-293	to	_	_	
2-13	294-303	determine	_	_	
2-14	304-307	the	_	_	
2-15	308-313	range	_	_	
2-16	314-322	distance	_	_	
2-17	322-323	.	_	_	

#Text=In the vergence method embodiments, the raw sensor information, the mapping information, the calculated distance, or any combination of these may be used in the determination of the placement and/or focus of the virtual image or images.
#Text=[0909] It is to be understood that the vergence method embodiments include the placement of a virtual image for one of the user's eyes or for both of the user's eyes.
3-1	324-326	In	_	_	
3-2	327-330	the	_	_	
3-3	331-339	vergence	_	_	
3-4	340-346	method	_	_	
3-5	347-358	embodiments	_	_	
3-6	358-359	,	_	_	
3-7	360-363	the	_	_	
3-8	364-367	raw	_	_	
3-9	368-374	sensor	_	_	
3-10	375-386	information	_	_	
3-11	386-387	,	_	_	
3-12	388-391	the	_	_	
3-13	392-399	mapping	_	_	
3-14	400-411	information	_	_	
3-15	411-412	,	_	_	
3-16	413-416	the	_	_	
3-17	417-427	calculated	_	_	
3-18	428-436	distance	_	_	
3-19	436-437	,	_	_	
3-20	438-440	or	_	_	
3-21	441-444	any	_	_	
3-22	445-456	combination	_	_	
3-23	457-459	of	_	_	
3-24	460-465	these	_	_	
3-25	466-469	may	_	_	
3-26	470-472	be	_	_	
3-27	473-477	used	_	_	
3-28	478-480	in	_	_	
3-29	481-484	the	_	_	
3-30	485-498	determination	_	_	
3-31	499-501	of	_	_	
3-32	502-505	the	_	_	
3-33	506-515	placement	_	_	
3-34	516-519	and	_	_	
3-35	519-520	/	_	_	
3-36	520-522	or	_	_	
3-37	523-528	focus	_	_	
3-38	529-531	of	_	_	
3-39	532-535	the	_	_	
3-40	536-543	virtual	_	_	
3-41	544-549	image	_	_	
3-42	550-552	or	_	_	
3-43	553-559	images	_	_	
3-44	559-560	.	_	_	
3-45	561-562	[	_	_	
3-46	562-566	0909	_	_	
3-47	566-567	]	_	_	
3-48	568-570	It	_	_	
3-49	571-573	is	_	_	
3-50	574-576	to	_	_	
3-51	577-579	be	_	_	
3-52	580-590	understood	_	_	
3-53	591-595	that	_	_	
3-54	596-599	the	_	_	
3-55	600-608	vergence	_	_	
3-56	609-615	method	_	_	
3-57	616-627	embodiments	_	_	
3-58	628-635	include	_	_	
3-59	636-639	the	_	_	
3-60	640-649	placement	_	_	
3-61	650-652	of	_	_	
3-62	653-654	a	_	_	
3-63	655-662	virtual	_	_	
3-64	663-668	image	_	_	
3-65	669-672	for	_	_	
3-66	673-676	one	_	_	
3-67	677-679	of	_	_	
3-68	680-683	the	_	_	
3-69	684-690	user's	_	_	
3-70	691-695	eyes	_	_	
3-71	696-698	or	_	_	
3-72	699-702	for	_	_	
3-73	703-707	both	_	_	
3-74	708-710	of	_	_	
3-75	711-714	the	_	_	
3-76	715-721	user's	_	_	
3-77	722-726	eyes	_	_	
3-78	726-727	.	_	_	

#Text=In some embodiments, one virtual image is provided to the user's left eye and a different virtual image is provided to the user's right eye.
4-1	728-730	In	_	_	
4-2	731-735	some	_	_	
4-3	736-747	embodiments	_	_	
4-4	747-748	,	_	_	
4-5	749-752	one	_	_	
4-6	753-760	virtual	_	_	
4-7	761-766	image	_	_	
4-8	767-769	is	_	_	
4-9	770-778	provided	_	_	
4-10	779-781	to	_	_	
4-11	782-785	the	_	_	
4-12	786-792	user's	_	_	
4-13	793-797	left	_	_	
4-14	798-801	eye	_	_	
4-15	802-805	and	_	_	
4-16	806-807	a	_	_	
4-17	808-817	different	_	_	
4-18	818-825	virtual	_	_	
4-19	826-831	image	_	_	
4-20	832-834	is	_	_	
4-21	835-843	provided	_	_	
4-22	844-846	to	_	_	
4-23	847-850	the	_	_	
4-24	851-857	user's	_	_	
4-25	858-863	right	_	_	
4-26	864-867	eye	_	_	
4-27	867-868	.	_	_	

#Text=In cases where multiple images are placed before the user, whether or not the images are the same or different, the placement may be simultaneous, at different times, or interlaced in time, e.g., the images are shown at a predetermined flicker rate or rates (e.g., 30, 60, and/or 180 Hz) with the image for the left eye being present when the image for the right eye is not and vice versa.
5-1	869-871	In	_	_	
5-2	872-877	cases	_	_	
5-3	878-883	where	_	_	
5-4	884-892	multiple	_	_	
5-5	893-899	images	_	_	
5-6	900-903	are	_	_	
5-7	904-910	placed	_	_	
5-8	911-917	before	_	_	
5-9	918-921	the	_	_	
5-10	922-926	user	_	_	
5-11	926-927	,	_	_	
5-12	928-935	whether	_	_	
5-13	936-938	or	_	_	
5-14	939-942	not	_	_	
5-15	943-946	the	_	_	
5-16	947-953	images	_	_	
5-17	954-957	are	_	_	
5-18	958-961	the	_	_	
5-19	962-966	same	_	_	
5-20	967-969	or	_	_	
5-21	970-979	different	_	_	
5-22	979-980	,	_	_	
5-23	981-984	the	_	_	
5-24	985-994	placement	_	_	
5-25	995-998	may	_	_	
5-26	999-1001	be	_	_	
5-27	1002-1014	simultaneous	_	_	
5-28	1014-1015	,	_	_	
5-29	1016-1018	at	_	_	
5-30	1019-1028	different	_	_	
5-31	1029-1034	times	_	_	
5-32	1034-1035	,	_	_	
5-33	1036-1038	or	_	_	
5-34	1039-1049	interlaced	_	_	
5-35	1050-1052	in	_	_	
5-36	1053-1057	time	_	_	
5-37	1057-1058	,	_	_	
5-38	1059-1062	e.g	_	_	
5-39	1062-1063	.	_	_	
5-40	1063-1064	,	_	_	
5-41	1065-1068	the	_	_	
5-42	1069-1075	images	_	_	
5-43	1076-1079	are	_	_	
5-44	1080-1085	shown	_	_	
5-45	1086-1088	at	_	_	
5-46	1089-1090	a	_	_	
5-47	1091-1104	predetermined	_	_	
5-48	1105-1112	flicker	_	_	
5-49	1113-1117	rate	_	_	
5-50	1118-1120	or	_	_	
5-51	1121-1126	rates	_	_	
5-52	1127-1128	(	_	_	
5-53	1128-1131	e.g	_	_	
5-54	1131-1132	.	_	_	
5-55	1132-1133	,	_	_	
5-56	1134-1136	30	_	_	
5-57	1136-1137	,	_	_	
5-58	1138-1140	60	_	_	
5-59	1140-1141	,	_	_	
5-60	1142-1145	and	_	_	
5-61	1145-1146	/	_	_	
5-62	1146-1148	or	_	_	
5-63	1149-1152	180	_	_	
5-64	1153-1155	Hz	_	_	
5-65	1155-1156	)	_	_	
5-66	1157-1161	with	_	_	
5-67	1162-1165	the	_	_	
5-68	1166-1171	image	_	_	
5-69	1172-1175	for	_	_	
5-70	1176-1179	the	_	_	
5-71	1180-1184	left	_	_	
5-72	1185-1188	eye	_	_	
5-73	1189-1194	being	_	_	
5-74	1195-1202	present	_	_	
5-75	1203-1207	when	_	_	
5-76	1208-1211	the	_	_	
5-77	1212-1217	image	_	_	
5-78	1218-1221	for	_	_	
5-79	1222-1225	the	_	_	
5-80	1226-1231	right	_	_	
5-81	1232-1235	eye	_	_	
5-82	1236-1238	is	_	_	
5-83	1239-1242	not	_	_	
5-84	1243-1246	and	_	_	
5-85	1247-1251	vice	_	_	
5-86	1252-1257	versa	_	_	
5-87	1257-1258	.	_	_	

#Text=In some embodiments, a virtual image is shown only to the person's dominant eye and in others a virtual image is shown only to the person's non-dominant eye.
6-1	1259-1261	In	_	_	
6-2	1262-1266	some	_	_	
6-3	1267-1278	embodiments	_	_	
6-4	1278-1279	,	_	_	
6-5	1280-1281	a	_	_	
6-6	1282-1289	virtual	_	_	
6-7	1290-1295	image	_	_	
6-8	1296-1298	is	_	_	
6-9	1299-1304	shown	_	_	
6-10	1305-1309	only	_	_	
6-11	1310-1312	to	_	_	
6-12	1313-1316	the	_	_	
6-13	1317-1325	person's	_	_	
6-14	1326-1334	dominant	_	_	
6-15	1335-1338	eye	_	_	
6-16	1339-1342	and	_	_	
6-17	1343-1345	in	_	_	
6-18	1346-1352	others	_	_	
6-19	1353-1354	a	_	_	
6-20	1355-1362	virtual	_	_	
6-21	1363-1368	image	_	_	
6-22	1369-1371	is	_	_	
6-23	1372-1377	shown	_	_	
6-24	1378-1382	only	_	_	
6-25	1383-1385	to	_	_	
6-26	1386-1389	the	_	_	
6-27	1390-1398	person's	_	_	
6-28	1399-1411	non-dominant	_	_	
6-29	1412-1415	eye	_	_	
6-30	1415-1416	.	_	_	

#Text=In some embodiments which employ images which are interlaced in time, virtual images of various objects which are located at various distances from the user are displayed in the manner described above; when the user looks from the real image of one object to the real image of another object, only the virtual image corresponding to the real image of the object being viewed will be seen by the user's brain.
#Text=[0910] In embodiments, the invention provides methods for providing a depth cue with augmented reality virtual objects or virtual information that can convey a wide range of perceived depth to a broad range of individuals with different eye characteristics.
7-1	1417-1419	In	_	_	
7-2	1420-1424	some	_	_	
7-3	1425-1436	embodiments	_	_	
7-4	1437-1442	which	_	_	
7-5	1443-1449	employ	_	_	
7-6	1450-1456	images	_	_	
7-7	1457-1462	which	_	_	
7-8	1463-1466	are	_	_	
7-9	1467-1477	interlaced	_	_	
7-10	1478-1480	in	_	_	
7-11	1481-1485	time	_	_	
7-12	1485-1486	,	_	_	
7-13	1487-1494	virtual	_	_	
7-14	1495-1501	images	_	_	
7-15	1502-1504	of	_	_	
7-16	1505-1512	various	_	_	
7-17	1513-1520	objects	_	_	
7-18	1521-1526	which	_	_	
7-19	1527-1530	are	_	_	
7-20	1531-1538	located	_	_	
7-21	1539-1541	at	_	_	
7-22	1542-1549	various	_	_	
7-23	1550-1559	distances	_	_	
7-24	1560-1564	from	_	_	
7-25	1565-1568	the	_	_	
7-26	1569-1573	user	_	_	
7-27	1574-1577	are	_	_	
7-28	1578-1587	displayed	_	_	
7-29	1588-1590	in	_	_	
7-30	1591-1594	the	_	_	
7-31	1595-1601	manner	_	_	
7-32	1602-1611	described	_	_	
7-33	1612-1617	above	_	_	
7-34	1617-1618	;	_	_	
7-35	1619-1623	when	_	_	
7-36	1624-1627	the	_	_	
7-37	1628-1632	user	_	_	
7-38	1633-1638	looks	_	_	
7-39	1639-1643	from	_	_	
7-40	1644-1647	the	_	_	
7-41	1648-1652	real	_	_	
7-42	1653-1658	image	_	_	
7-43	1659-1661	of	_	_	
7-44	1662-1665	one	_	_	
7-45	1666-1672	object	_	_	
7-46	1673-1675	to	_	_	
7-47	1676-1679	the	_	_	
7-48	1680-1684	real	_	_	
7-49	1685-1690	image	_	_	
7-50	1691-1693	of	_	_	
7-51	1694-1701	another	_	_	
7-52	1702-1708	object	_	_	
7-53	1708-1709	,	_	_	
7-54	1710-1714	only	_	_	
7-55	1715-1718	the	_	_	
7-56	1719-1726	virtual	_	_	
7-57	1727-1732	image	_	_	
7-58	1733-1746	corresponding	_	_	
7-59	1747-1749	to	_	_	
7-60	1750-1753	the	_	_	
7-61	1754-1758	real	_	_	
7-62	1759-1764	image	_	_	
7-63	1765-1767	of	_	_	
7-64	1768-1771	the	_	_	
7-65	1772-1778	object	_	_	
7-66	1779-1784	being	_	_	
7-67	1785-1791	viewed	_	_	
7-68	1792-1796	will	_	_	
7-69	1797-1799	be	_	_	
7-70	1800-1804	seen	_	_	
7-71	1805-1807	by	_	_	
7-72	1808-1811	the	_	_	
7-73	1812-1818	user's	_	_	
7-74	1819-1824	brain	_	_	
7-75	1824-1825	.	_	_	
7-76	1826-1827	[	_	_	
7-77	1827-1831	0910	_	_	
7-78	1831-1832	]	_	_	
7-79	1833-1835	In	_	_	
7-80	1836-1847	embodiments	_	_	
7-81	1847-1848	,	_	_	
7-82	1849-1852	the	_	_	
7-83	1853-1862	invention	_	_	
7-84	1863-1871	provides	_	_	
7-85	1872-1879	methods	_	_	
7-86	1880-1883	for	_	_	
7-87	1884-1893	providing	_	_	
7-88	1894-1895	a	_	_	
7-89	1896-1901	depth	_	_	
7-90	1902-1905	cue	_	_	
7-91	1906-1910	with	_	_	
7-92	1911-1920	augmented	_	_	
7-93	1921-1928	reality	_	_	
7-94	1929-1936	virtual	_	_	
7-95	1937-1944	objects	_	_	
7-96	1945-1947	or	_	_	
7-97	1948-1955	virtual	_	_	
7-98	1956-1967	information	_	_	
7-99	1968-1972	that	_	_	
7-100	1973-1976	can	_	_	
7-101	1977-1983	convey	_	_	
7-102	1984-1985	a	_	_	
7-103	1986-1990	wide	_	_	
7-104	1991-1996	range	_	_	
7-105	1997-1999	of	_	_	
7-106	2000-2009	perceived	_	_	
7-107	2010-2015	depth	_	_	
7-108	2016-2018	to	_	_	
7-109	2019-2020	a	_	_	
7-110	2021-2026	broad	_	_	
7-111	2027-2032	range	_	_	
7-112	2033-2035	of	_	_	
7-113	2036-2047	individuals	_	_	
7-114	2048-2052	with	_	_	
7-115	2053-2062	different	_	_	
7-116	2063-2066	eye	_	_	
7-117	2067-2082	characteristics	_	_	
7-118	2082-2083	.	_	_	

#Text=These depth cue method embodiments of the present invention use differences in the lateral positioning or disparity of the augmented reality images provided to the two eyes of the individual to provide differences in the vergence of the virtual objects or virtual information that convey a sense of depth.
8-1	2084-2089	These	_	_	
8-2	2090-2095	depth	_	_	
8-3	2096-2099	cue	_	_	
8-4	2100-2106	method	_	_	
8-5	2107-2118	embodiments	_	_	
8-6	2119-2121	of	_	_	
8-7	2122-2125	the	_	_	
8-8	2126-2133	present	_	_	
8-9	2134-2143	invention	_	_	
8-10	2144-2147	use	_	_	
8-11	2148-2159	differences	_	_	
8-12	2160-2162	in	_	_	
8-13	2163-2166	the	_	_	
8-14	2167-2174	lateral	_	_	
8-15	2175-2186	positioning	_	_	
8-16	2187-2189	or	_	_	
8-17	2190-2199	disparity	_	_	
8-18	2200-2202	of	_	_	
8-19	2203-2206	the	_	_	
8-20	2207-2216	augmented	_	_	
8-21	2217-2224	reality	_	_	
8-22	2225-2231	images	_	_	
8-23	2232-2240	provided	_	_	
8-24	2241-2243	to	_	_	
8-25	2244-2247	the	_	_	
8-26	2248-2251	two	_	_	
8-27	2252-2256	eyes	_	_	
8-28	2257-2259	of	_	_	
8-29	2260-2263	the	_	_	
8-30	2264-2274	individual	_	_	
8-31	2275-2277	to	_	_	
8-32	2278-2285	provide	_	_	
8-33	2286-2297	differences	_	_	
8-34	2298-2300	in	_	_	
8-35	2301-2304	the	_	_	
8-36	2305-2313	vergence	_	_	
8-37	2314-2316	of	_	_	
8-38	2317-2320	the	_	_	
8-39	2321-2328	virtual	_	_	
8-40	2329-2336	objects	_	_	
8-41	2337-2339	or	_	_	
8-42	2340-2347	virtual	_	_	
8-43	2348-2359	information	_	_	
8-44	2360-2364	that	_	_	
8-45	2365-2371	convey	_	_	
8-46	2372-2373	a	_	_	
8-47	2374-2379	sense	_	_	
8-48	2380-2382	of	_	_	
8-49	2383-2388	depth	_	_	
8-50	2388-2389	.	_	_	

#Text=One advantage of these methods is that the lateral shifting of the augmented reality images can be different for different portions of the augmented reality images so that the perceived depth is different for those portions.
9-1	2390-2393	One	_	_	
9-2	2394-2403	advantage	_	_	
9-3	2404-2406	of	_	_	
9-4	2407-2412	these	_	_	
9-5	2413-2420	methods	_	_	
9-6	2421-2423	is	_	_	
9-7	2424-2428	that	_	_	
9-8	2429-2432	the	_	_	
9-9	2433-2440	lateral	_	_	
9-10	2441-2449	shifting	_	_	
9-11	2450-2452	of	_	_	
9-12	2453-2456	the	_	_	
9-13	2457-2466	augmented	_	_	
9-14	2467-2474	reality	_	_	
9-15	2475-2481	images	_	_	
9-16	2482-2485	can	_	_	
9-17	2486-2488	be	_	_	
9-18	2489-2498	different	_	_	
9-19	2499-2502	for	_	_	
9-20	2503-2512	different	_	_	
9-21	2513-2521	portions	_	_	
9-22	2522-2524	of	_	_	
9-23	2525-2528	the	_	_	
9-24	2529-2538	augmented	_	_	
9-25	2539-2546	reality	_	_	
9-26	2547-2553	images	_	_	
9-27	2554-2556	so	_	_	
9-28	2557-2561	that	_	_	
9-29	2562-2565	the	_	_	
9-30	2566-2575	perceived	_	_	
9-31	2576-2581	depth	_	_	
9-32	2582-2584	is	_	_	
9-33	2585-2594	different	_	_	
9-34	2595-2598	for	_	_	
9-35	2599-2604	those	_	_	
9-36	2605-2613	portions	_	_	
9-37	2613-2614	.	_	_	

#Text=In addition, the lateral shifting can be done through image processing of the portions of the augmented reality images.
10-1	2615-2617	In	_	_	
10-2	2618-2626	addition	_	_	
10-3	2626-2627	,	_	_	
10-4	2628-2631	the	_	_	
10-5	2632-2639	lateral	_	_	
10-6	2640-2648	shifting	_	_	
10-7	2649-2652	can	_	_	
10-8	2653-2655	be	_	_	
10-9	2656-2660	done	_	_	
10-10	2661-2668	through	_	_	
10-11	2669-2674	image	_	_	
10-12	2675-2685	processing	_	_	
10-13	2686-2688	of	_	_	
10-14	2689-2692	the	_	_	
10-15	2693-2701	portions	_	_	
10-16	2702-2704	of	_	_	
10-17	2705-2708	the	_	_	
10-18	2709-2718	augmented	_	_	
10-19	2719-2726	reality	_	_	
10-20	2727-2733	images	_	_	
10-21	2733-2734	.	_	_	

#Text=The user can experience a full range of perceived depth through this method from as near as the individual can focus to infinity regardless of the individual's age.
#Text=[0911] In order to better understand these depth cue method embodiments of the present invention, it is useful to keep in mind that in some aspects of augmented reality, head mounted displays are used to add images of virtual objects or virtual information that are associated with the view of a scene as seen by a user.
11-1	2735-2738	The	_	_	
11-2	2739-2743	user	_	_	
11-3	2744-2747	can	_	_	
11-4	2748-2758	experience	_	_	
11-5	2759-2760	a	_	_	
11-6	2761-2765	full	_	_	
11-7	2766-2771	range	_	_	
11-8	2772-2774	of	_	_	
11-9	2775-2784	perceived	_	_	
11-10	2785-2790	depth	_	_	
11-11	2791-2798	through	_	_	
11-12	2799-2803	this	_	_	
11-13	2804-2810	method	_	_	
11-14	2811-2815	from	_	_	
11-15	2816-2818	as	_	_	
11-16	2819-2823	near	_	_	
11-17	2824-2826	as	_	_	
11-18	2827-2830	the	_	_	
11-19	2831-2841	individual	_	_	
11-20	2842-2845	can	_	_	
11-21	2846-2851	focus	_	_	
11-22	2852-2854	to	_	_	
11-23	2855-2863	infinity	_	_	
11-24	2864-2874	regardless	_	_	
11-25	2875-2877	of	_	_	
11-26	2878-2881	the	_	_	
11-27	2882-2894	individual's	_	_	
11-28	2895-2898	age	_	_	
11-29	2898-2899	.	_	_	
11-30	2900-2901	[	_	_	
11-31	2901-2905	0911	_	_	
11-32	2905-2906	]	_	_	
11-33	2907-2909	In	_	_	
11-34	2910-2915	order	_	_	
11-35	2916-2918	to	_	_	
11-36	2919-2925	better	_	_	
11-37	2926-2936	understand	_	_	
11-38	2937-2942	these	_	_	
11-39	2943-2948	depth	_	_	
11-40	2949-2952	cue	_	_	
11-41	2953-2959	method	_	_	
11-42	2960-2971	embodiments	_	_	
11-43	2972-2974	of	_	_	
11-44	2975-2978	the	_	_	
11-45	2979-2986	present	_	_	
11-46	2987-2996	invention	_	_	
11-47	2996-2997	,	_	_	
11-48	2998-3000	it	_	_	
11-49	3001-3003	is	_	_	
11-50	3004-3010	useful	_	_	
11-51	3011-3013	to	_	_	
11-52	3014-3018	keep	_	_	
11-53	3019-3021	in	_	_	
11-54	3022-3026	mind	_	_	
11-55	3027-3031	that	_	_	
11-56	3032-3034	in	_	_	
11-57	3035-3039	some	_	_	
11-58	3040-3047	aspects	_	_	
11-59	3048-3050	of	_	_	
11-60	3051-3060	augmented	_	_	
11-61	3061-3068	reality	_	_	
11-62	3068-3069	,	_	_	
11-63	3070-3074	head	_	_	
11-64	3075-3082	mounted	_	_	
11-65	3083-3091	displays	_	_	
11-66	3092-3095	are	_	_	
11-67	3096-3100	used	_	_	
11-68	3101-3103	to	_	_	
11-69	3104-3107	add	_	_	
11-70	3108-3114	images	_	_	
11-71	3115-3117	of	_	_	
11-72	3118-3125	virtual	_	_	
11-73	3126-3133	objects	_	_	
11-74	3134-3136	or	_	_	
11-75	3137-3144	virtual	_	_	
11-76	3145-3156	information	_	_	
11-77	3157-3161	that	_	_	
11-78	3162-3165	are	_	_	
11-79	3166-3176	associated	_	_	
11-80	3177-3181	with	_	_	
11-81	3182-3185	the	_	_	
11-82	3186-3190	view	_	_	
11-83	3191-3193	of	_	_	
11-84	3194-3195	a	_	_	
11-85	3196-3201	scene	_	_	
11-86	3202-3204	as	_	_	
11-87	3205-3209	seen	_	_	
11-88	3210-3212	by	_	_	
11-89	3213-3214	a	_	_	
11-90	3215-3219	user	_	_	
11-91	3219-3220	.	_	_	

#Text=To add additional effects to the perception of the augmented it is useful to place the virtual objects or virtual information at a perceived depth in the scene.
12-1	3221-3223	To	_	_	
12-2	3224-3227	add	_	_	
12-3	3228-3238	additional	_	_	
12-4	3239-3246	effects	_	_	
12-5	3247-3249	to	_	_	
12-6	3250-3253	the	_	_	
12-7	3254-3264	perception	_	_	
12-8	3265-3267	of	_	_	
12-9	3268-3271	the	_	_	
12-10	3272-3281	augmented	_	_	
12-11	3282-3284	it	_	_	
12-12	3285-3287	is	_	_	
12-13	3288-3294	useful	_	_	
12-14	3295-3297	to	_	_	
12-15	3298-3303	place	_	_	
12-16	3304-3307	the	_	_	
12-17	3308-3315	virtual	_	_	
12-18	3316-3323	objects	_	_	
12-19	3324-3326	or	_	_	
12-20	3327-3334	virtual	_	_	
12-21	3335-3346	information	_	_	
12-22	3347-3349	at	_	_	
12-23	3350-3351	a	_	_	
12-24	3352-3361	perceived	_	_	
12-25	3362-3367	depth	_	_	
12-26	3368-3370	in	_	_	
12-27	3371-3374	the	_	_	
12-28	3375-3380	scene	_	_	
12-29	3380-3381	.	_	_	

#Text=As an example, a virtual label can be placed onto an object in a scene such as the name of a building.
13-1	3382-3384	As	_	_	
13-2	3385-3387	an	_	_	
13-3	3388-3395	example	_	_	
13-4	3395-3396	,	_	_	
13-5	3397-3398	a	_	_	
13-6	3399-3406	virtual	_	_	
13-7	3407-3412	label	_	_	
13-8	3413-3416	can	_	_	
13-9	3417-3419	be	_	_	
13-10	3420-3426	placed	_	_	
13-11	3427-3431	onto	_	_	
13-12	3432-3434	an	_	_	
13-13	3435-3441	object	_	_	
13-14	3442-3444	in	_	_	
13-15	3445-3446	a	_	_	
13-16	3447-3452	scene	_	_	
13-17	3453-3457	such	_	_	
13-18	3458-3460	as	_	_	
13-19	3461-3464	the	_	_	
13-20	3465-3469	name	_	_	
13-21	3470-3472	of	_	_	
13-22	3473-3474	a	_	_	
13-23	3475-3483	building	_	_	
13-24	3483-3484	.	_	_	

#Text=The perceived association of the virtual label with the building is enhanced if the label and the building are perceived by the user to be at the same depth in the scene.
14-1	3485-3488	The	_	_	
14-2	3489-3498	perceived	_	_	
14-3	3499-3510	association	_	_	
14-4	3511-3513	of	_	_	
14-5	3514-3517	the	_	_	
14-6	3518-3525	virtual	_	_	
14-7	3526-3531	label	_	_	
14-8	3532-3536	with	_	_	
14-9	3537-3540	the	_	_	
14-10	3541-3549	building	_	_	
14-11	3550-3552	is	_	_	
14-12	3553-3561	enhanced	_	_	
14-13	3562-3564	if	_	_	
14-14	3565-3568	the	_	_	
14-15	3569-3574	label	_	_	
14-16	3575-3578	and	_	_	
14-17	3579-3582	the	_	_	
14-18	3583-3591	building	_	_	
14-19	3592-3595	are	_	_	
14-20	3596-3605	perceived	_	_	
14-21	3606-3608	by	_	_	
14-22	3609-3612	the	_	_	
14-23	3613-3617	user	_	_	
14-24	3618-3620	to	_	_	
14-25	3621-3623	be	_	_	
14-26	3624-3626	at	_	_	
14-27	3627-3630	the	_	_	
14-28	3631-3635	same	_	_	
14-29	3636-3641	depth	_	_	
14-30	3642-3644	in	_	_	
14-31	3645-3648	the	_	_	
14-32	3649-3654	scene	_	_	
14-33	3654-3655	.	_	_	

#Text=Head mounted displays with see-through capabilities are well suited to providing augmented reality information such as labels and objects because they provide the user with a clear view of the environment.
15-1	3656-3660	Head	_	_	
15-2	3661-3668	mounted	_	_	
15-3	3669-3677	displays	_	_	
15-4	3678-3682	with	_	_	
15-5	3683-3694	see-through	_	_	
15-6	3695-3707	capabilities	_	_	
15-7	3708-3711	are	_	_	
15-8	3712-3716	well	_	_	
15-9	3717-3723	suited	_	_	
15-10	3724-3726	to	_	_	
15-11	3727-3736	providing	_	_	
15-12	3737-3746	augmented	_	_	
15-13	3747-3754	reality	_	_	
15-14	3755-3766	information	_	_	
15-15	3767-3771	such	_	_	
15-16	3772-3774	as	_	_	
15-17	3775-3781	labels	_	_	
15-18	3782-3785	and	_	_	
15-19	3786-3793	objects	_	_	
15-20	3794-3801	because	_	_	
15-21	3802-3806	they	_	_	
15-22	3807-3814	provide	_	_	
15-23	3815-3818	the	_	_	
15-24	3819-3823	user	_	_	
15-25	3824-3828	with	_	_	
15-26	3829-3830	a	_	_	
15-27	3831-3836	clear	_	_	
15-28	3837-3841	view	_	_	
15-29	3842-3844	of	_	_	
15-30	3845-3848	the	_	_	
15-31	3849-3860	environment	_	_	
15-32	3860-3861	.	_	_	

#Text=However, for the augmented reality information to be of value, it must be easily associated with the objects in the environment and as such the positioning of the augmented reality information relative to the objects in the see-through view is important.
16-1	3862-3869	However	_	_	
16-2	3869-3870	,	_	_	
16-3	3871-3874	for	_	_	
16-4	3875-3878	the	_	_	
16-5	3879-3888	augmented	_	_	
16-6	3889-3896	reality	_	_	
16-7	3897-3908	information	_	_	
16-8	3909-3911	to	_	_	
16-9	3912-3914	be	_	_	
16-10	3915-3917	of	_	_	
16-11	3918-3923	value	_	_	
16-12	3923-3924	,	_	_	
16-13	3925-3927	it	_	_	
16-14	3928-3932	must	_	_	
16-15	3933-3935	be	_	_	
16-16	3936-3942	easily	_	_	
16-17	3943-3953	associated	_	_	
16-18	3954-3958	with	_	_	
16-19	3959-3962	the	_	_	
16-20	3963-3970	objects	_	_	
16-21	3971-3973	in	_	_	
16-22	3974-3977	the	_	_	
16-23	3978-3989	environment	_	_	
16-24	3990-3993	and	_	_	
16-25	3994-3996	as	_	_	
16-26	3997-4001	such	_	_	
16-27	4002-4005	the	_	_	
16-28	4006-4017	positioning	_	_	
16-29	4018-4020	of	_	_	
16-30	4021-4024	the	_	_	
16-31	4025-4034	augmented	_	_	
16-32	4035-4042	reality	_	_	
16-33	4043-4054	information	_	_	
16-34	4055-4063	relative	_	_	
16-35	4064-4066	to	_	_	
16-36	4067-4070	the	_	_	
16-37	4071-4078	objects	_	_	
16-38	4079-4081	in	_	_	
16-39	4082-4085	the	_	_	
16-40	4086-4097	see-through	_	_	
16-41	4098-4102	view	_	_	
16-42	4103-4105	is	_	_	
16-43	4106-4115	important	_	_	
16-44	4115-4116	.	_	_	

#Text=While horizontal and vertical positioning of augmented reality information is relatively straight forward if the head mounted display has a camera that can be calibrated to the see-through view, the depth positioning is more complicated.
17-1	4117-4122	While	_	_	
17-2	4123-4133	horizontal	_	_	
17-3	4134-4137	and	_	_	
17-4	4138-4146	vertical	_	_	
17-5	4147-4158	positioning	_	_	
17-6	4159-4161	of	_	_	
17-7	4162-4171	augmented	_	_	
17-8	4172-4179	reality	_	_	
17-9	4180-4191	information	_	_	
17-10	4192-4194	is	_	_	
17-11	4195-4205	relatively	_	_	
17-12	4206-4214	straight	_	_	
17-13	4215-4222	forward	_	_	
17-14	4223-4225	if	_	_	
17-15	4226-4229	the	_	_	
17-16	4230-4234	head	_	_	
17-17	4235-4242	mounted	_	_	
17-18	4243-4250	display	_	_	
17-19	4251-4254	has	_	_	
17-20	4255-4256	a	_	_	
17-21	4257-4263	camera	_	_	
17-22	4264-4268	that	_	_	
17-23	4269-4272	can	_	_	
17-24	4273-4275	be	_	_	
17-25	4276-4286	calibrated	_	_	
17-26	4287-4289	to	_	_	
17-27	4290-4293	the	_	_	
17-28	4294-4305	see-through	_	_	
17-29	4306-4310	view	_	_	
17-30	4310-4311	,	_	_	
17-31	4312-4315	the	_	_	
17-32	4316-4321	depth	_	_	
17-33	4322-4333	positioning	_	_	
17-34	4334-4336	is	_	_	
17-35	4337-4341	more	_	_	
17-36	4342-4353	complicated	_	_	
17-37	4353-4354	.	_	_	

#Text=U.S.
18-1	4355-4358	U.S	_	_	
18-2	4358-4359	.	_	_	

#Text=Pat.
19-1	4360-4363	Pat	_	_	
19-2	4363-4364	.	_	_	

#Text=No. 6,690,393 describes a method for positioning 2D labels in a 3D virtual world.
20-1	4365-4367	No	_	_	
20-2	4367-4368	.	_	_	
20-3	4369-4378	6,690,393	_	_	
20-4	4379-4388	describes	_	_	
20-5	4389-4390	a	*[1]	21-3[2_1]	
20-6	4391-4397	method	*[1]	_	
20-7	4398-4401	for	*[1]	_	
20-8	4402-4413	positioning	*[1]	_	
20-9	4414-4416	2D	*[1]	_	
20-10	4417-4423	labels	*[1]	_	
20-11	4424-4426	in	*[1]	_	
20-12	4427-4428	a	*[1]	_	
20-13	4429-4431	3D	*[1]	_	
20-14	4432-4439	virtual	*[1]	_	
20-15	4440-4445	world	*[1]	_	
20-16	4445-4446	.	_	_	

#Text=However, this method is not directed at displays with a see-through view where the majority of the image the user sees is not provided digitally and as such the 3D location of objects is not known.
21-1	4447-4454	However	_	_	
21-2	4454-4455	,	_	_	
21-3	4456-4460	this	*[2]	_	
21-4	4461-4467	method	*[2]	_	
21-5	4468-4470	is	_	_	
21-6	4471-4474	not	_	_	
21-7	4475-4483	directed	_	_	
21-8	4484-4486	at	_	_	
21-9	4487-4495	displays	_	_	
21-10	4496-4500	with	_	_	
21-11	4501-4502	a	_	_	
21-12	4503-4514	see-through	_	_	
21-13	4515-4519	view	_	_	
21-14	4520-4525	where	_	_	
21-15	4526-4529	the	_	_	
21-16	4530-4538	majority	_	_	
21-17	4539-4541	of	_	_	
21-18	4542-4545	the	_	_	
21-19	4546-4551	image	_	_	
21-20	4552-4555	the	_	_	
21-21	4556-4560	user	_	_	
21-22	4561-4565	sees	_	_	
21-23	4566-4568	is	_	_	
21-24	4569-4572	not	_	_	
21-25	4573-4581	provided	_	_	
21-26	4582-4591	digitally	_	_	
21-27	4592-4595	and	_	_	
21-28	4596-4598	as	_	_	
21-29	4599-4603	such	_	_	
21-30	4604-4607	the	_	_	
21-31	4608-4610	3D	_	_	
21-32	4611-4619	location	_	_	
21-33	4620-4622	of	_	_	
21-34	4623-4630	objects	_	_	
21-35	4631-4633	is	_	_	
21-36	4634-4637	not	_	_	
21-37	4638-4643	known	_	_	
21-38	4643-4644	.	_	_	

#Text=U.S.
22-1	4645-4648	U.S	_	_	
22-2	4648-4649	.	_	_	

#Text=Pat.
23-1	4650-4653	Pat	_	_	
23-2	4653-4654	.	_	_	

#Text=No. 7,907,166 describes a robotic surgical system using a stereo viewer in which telestration graphics are overlaid onto stereo images of an operating site.
24-1	4655-4657	No	_	_	
24-2	4657-4658	.	_	_	
24-3	4659-4668	7,907,166	_	_	
24-4	4669-4678	describes	_	_	
24-5	4679-4680	a	_	_	
24-6	4681-4688	robotic	_	_	
24-7	4689-4697	surgical	_	_	
24-8	4698-4704	system	_	_	
24-9	4705-4710	using	_	_	
24-10	4711-4712	a	_	_	
24-11	4713-4719	stereo	_	_	
24-12	4720-4726	viewer	_	_	
24-13	4727-4729	in	_	_	
24-14	4730-4735	which	_	_	
24-15	4736-4748	telestration	_	_	
24-16	4749-4757	graphics	_	_	
24-17	4758-4761	are	_	_	
24-18	4762-4770	overlaid	_	_	
24-19	4771-4775	onto	_	_	
24-20	4776-4782	stereo	_	_	
24-21	4783-4789	images	_	_	
24-22	4790-4792	of	_	_	
24-23	4793-4795	an	_	_	
24-24	4796-4805	operating	_	_	
24-25	4806-4810	site	_	_	
24-26	4810-4811	.	_	_	

#Text=However, similar to the method described in U.S.
25-1	4812-4819	However	_	_	
25-2	4819-4820	,	_	_	
25-3	4821-4828	similar	_	_	
25-4	4829-4831	to	_	_	
25-5	4832-4835	the	_	_	
25-6	4836-4842	method	_	_	
25-7	4843-4852	described	_	_	
25-8	4853-4855	in	_	_	
25-9	4856-4859	U.S	_	_	
25-10	4859-4860	.	_	_	

#Text=Pat.
26-1	4861-4864	Pat	_	_	
26-2	4864-4865	.	_	_	

#Text=No. 6,690,393, this system uses captured images which are then manipulated to add graphics and as such does not address the unique situation with see-through displays wherein the majority of the image is not provided digitally and the relative locations of objects that the user sees are not known.
27-1	4866-4868	No	_	_	
27-2	4868-4869	.	_	_	
27-3	4870-4879	6,690,393	_	_	
27-4	4879-4880	,	_	_	
27-5	4881-4885	this	_	_	
27-6	4886-4892	system	_	_	
27-7	4893-4897	uses	_	_	
27-8	4898-4906	captured	_	_	
27-9	4907-4913	images	_	_	
27-10	4914-4919	which	_	_	
27-11	4920-4923	are	_	_	
27-12	4924-4928	then	_	_	
27-13	4929-4940	manipulated	_	_	
27-14	4941-4943	to	_	_	
27-15	4944-4947	add	_	_	
27-16	4948-4956	graphics	_	_	
27-17	4957-4960	and	_	_	
27-18	4961-4963	as	_	_	
27-19	4964-4968	such	_	_	
27-20	4969-4973	does	_	_	
27-21	4974-4977	not	_	_	
27-22	4978-4985	address	_	_	
27-23	4986-4989	the	_	_	
27-24	4990-4996	unique	_	_	
27-25	4997-5006	situation	_	_	
27-26	5007-5011	with	_	_	
27-27	5012-5023	see-through	_	_	
27-28	5024-5032	displays	_	_	
27-29	5033-5040	wherein	_	_	
27-30	5041-5044	the	_	_	
27-31	5045-5053	majority	_	_	
27-32	5054-5056	of	_	_	
27-33	5057-5060	the	_	_	
27-34	5061-5066	image	_	_	
27-35	5067-5069	is	_	_	
27-36	5070-5073	not	_	_	
27-37	5074-5082	provided	_	_	
27-38	5083-5092	digitally	_	_	
27-39	5093-5096	and	_	_	
27-40	5097-5100	the	_	_	
27-41	5101-5109	relative	_	_	
27-42	5110-5119	locations	_	_	
27-43	5120-5122	of	_	_	
27-44	5123-5130	objects	_	_	
27-45	5131-5135	that	_	_	
27-46	5136-5139	the	_	_	
27-47	5140-5144	user	_	_	
27-48	5145-5149	sees	_	_	
27-49	5150-5153	are	_	_	
27-50	5154-5157	not	_	_	
27-51	5158-5163	known	_	_	
27-52	5163-5164	.	_	_	

#Text=Another prior art method for augmented reality is to adjust the focus of the virtual objects or virtual information so that the user perceives differences in focus depth that provide a depth cue to the user.
28-1	5165-5172	Another	_	_	
28-2	5173-5178	prior	_	_	
28-3	5179-5182	art	_	_	
28-4	5183-5189	method	_	_	
28-5	5190-5193	for	_	_	
28-6	5194-5203	augmented	_	_	
28-7	5204-5211	reality	_	_	
28-8	5212-5214	is	_	_	
28-9	5215-5217	to	_	_	
28-10	5218-5224	adjust	_	_	
28-11	5225-5228	the	_	_	
28-12	5229-5234	focus	_	_	
28-13	5235-5237	of	_	_	
28-14	5238-5241	the	_	_	
28-15	5242-5249	virtual	_	_	
28-16	5250-5257	objects	_	_	
28-17	5258-5260	or	_	_	
28-18	5261-5268	virtual	_	_	
28-19	5269-5280	information	_	_	
28-20	5281-5283	so	_	_	
28-21	5284-5288	that	_	_	
28-22	5289-5292	the	_	_	
28-23	5293-5297	user	_	_	
28-24	5298-5307	perceives	_	_	
28-25	5308-5319	differences	_	_	
28-26	5320-5322	in	_	_	
28-27	5323-5328	focus	_	_	
28-28	5329-5334	depth	_	_	
28-29	5335-5339	that	_	_	
28-30	5340-5347	provide	_	_	
28-31	5348-5349	a	_	_	
28-32	5350-5355	depth	_	_	
28-33	5356-5359	cue	_	_	
28-34	5360-5362	to	_	_	
28-35	5363-5366	the	_	_	
28-36	5367-5371	user	_	_	
28-37	5371-5372	.	_	_	

#Text=As the user has to refocus his/her eyes to look at objects in the scene and to look at the virtual objects or virtual information, the user perceives an associated depth.
29-1	5373-5375	As	_	_	
29-2	5376-5379	the	_	_	
29-3	5380-5384	user	_	_	
29-4	5385-5388	has	_	_	
29-5	5389-5391	to	_	_	
29-6	5392-5399	refocus	_	_	
29-7	5400-5403	his	_	_	
29-8	5403-5404	/	_	_	
29-9	5404-5407	her	_	_	
29-10	5408-5412	eyes	_	_	
29-11	5413-5415	to	_	_	
29-12	5416-5420	look	_	_	
29-13	5421-5423	at	_	_	
29-14	5424-5431	objects	_	_	
29-15	5432-5434	in	_	_	
29-16	5435-5438	the	_	_	
29-17	5439-5444	scene	_	_	
29-18	5445-5448	and	_	_	
29-19	5449-5451	to	_	_	
29-20	5452-5456	look	_	_	
29-21	5457-5459	at	_	_	
29-22	5460-5463	the	_	_	
29-23	5464-5471	virtual	_	_	
29-24	5472-5479	objects	_	_	
29-25	5480-5482	or	_	_	
29-26	5483-5490	virtual	_	_	
29-27	5491-5502	information	_	_	
29-28	5502-5503	,	_	_	
29-29	5504-5507	the	_	_	
29-30	5508-5512	user	_	_	
29-31	5513-5522	perceives	_	_	
29-32	5523-5525	an	_	_	
29-33	5526-5536	associated	_	_	
29-34	5537-5542	depth	_	_	
29-35	5542-5543	.	_	_	

#Text=However, the range of depth that can be associated with focus is limited by the accommodation that the user's eyes are capable of This accommodation can be limited in some individuals particularly if the individual is older when eyes lose much of their accommodation range.
30-1	5544-5551	However	_	_	
30-2	5551-5552	,	_	_	
30-3	5553-5556	the	_	_	
30-4	5557-5562	range	_	_	
30-5	5563-5565	of	_	_	
30-6	5566-5571	depth	_	_	
30-7	5572-5576	that	_	_	
30-8	5577-5580	can	_	_	
30-9	5581-5583	be	_	_	
30-10	5584-5594	associated	_	_	
30-11	5595-5599	with	_	_	
30-12	5600-5605	focus	_	_	
30-13	5606-5608	is	_	_	
30-14	5609-5616	limited	_	_	
30-15	5617-5619	by	_	_	
30-16	5620-5623	the	_	_	
30-17	5624-5637	accommodation	_	_	
30-18	5638-5642	that	_	_	
30-19	5643-5646	the	_	_	
30-20	5647-5653	user's	_	_	
30-21	5654-5658	eyes	_	_	
30-22	5659-5662	are	_	_	
30-23	5663-5670	capable	_	_	
30-24	5671-5673	of	_	_	
30-25	5674-5678	This	_	_	
30-26	5679-5692	accommodation	_	_	
30-27	5693-5696	can	_	_	
30-28	5697-5699	be	_	_	
30-29	5700-5707	limited	_	_	
30-30	5708-5710	in	_	_	
30-31	5711-5715	some	_	_	
30-32	5716-5727	individuals	_	_	
30-33	5728-5740	particularly	_	_	
30-34	5741-5743	if	_	_	
30-35	5744-5747	the	_	_	
30-36	5748-5758	individual	_	_	
30-37	5759-5761	is	_	_	
30-38	5762-5767	older	_	_	
30-39	5768-5772	when	_	_	
30-40	5773-5777	eyes	_	_	
30-41	5778-5782	lose	_	_	
30-42	5783-5787	much	_	_	
30-43	5788-5790	of	_	_	
30-44	5791-5796	their	_	_	
30-45	5797-5810	accommodation	_	_	
30-46	5811-5816	range	_	_	
30-47	5816-5817	.	_	_	

#Text=In addition, the accommodation range is different depending on whether the user is near sighted or far sighted.
31-1	5818-5820	In	_	_	
31-2	5821-5829	addition	_	_	
31-3	5829-5830	,	_	_	
31-4	5831-5834	the	_	_	
31-5	5835-5848	accommodation	_	_	
31-6	5849-5854	range	_	_	
31-7	5855-5857	is	_	_	
31-8	5858-5867	different	_	_	
31-9	5868-5877	depending	_	_	
31-10	5878-5880	on	_	_	
31-11	5881-5888	whether	_	_	
31-12	5889-5892	the	_	_	
31-13	5893-5897	user	_	_	
31-14	5898-5900	is	_	_	
31-15	5901-5905	near	_	_	
31-16	5906-5913	sighted	_	_	
31-17	5914-5916	or	_	_	
31-18	5917-5920	far	_	_	
31-19	5921-5928	sighted	_	_	
31-20	5928-5929	.	_	_	

#Text=These factors make the result of using focus cues unreliable for a large population of user's with different ages and different eye characteristics.
32-1	5930-5935	These	_	_	
32-2	5936-5943	factors	_	_	
32-3	5944-5948	make	_	_	
32-4	5949-5952	the	_	_	
32-5	5953-5959	result	_	_	
32-6	5960-5962	of	_	_	
32-7	5963-5968	using	_	_	
32-8	5969-5974	focus	_	_	
32-9	5975-5979	cues	_	_	
32-10	5980-5990	unreliable	_	_	
32-11	5991-5994	for	_	_	
32-12	5995-5996	a	_	_	
32-13	5997-6002	large	_	_	
32-14	6003-6013	population	_	_	
32-15	6014-6016	of	_	_	
32-16	6017-6023	user's	_	_	
32-17	6024-6028	with	_	_	
32-18	6029-6038	different	_	_	
32-19	6039-6043	ages	_	_	
32-20	6044-6047	and	_	_	
32-21	6048-6057	different	_	_	
32-22	6058-6061	eye	_	_	
32-23	6062-6077	characteristics	_	_	
32-24	6077-6078	.	_	_	

#Text=Therefore, the need persists beyond what is available in the prior art for a widely useable method for associating depth information with augmented reality.
#Text=[0912] Some of the depth cue method embodiments of the present invention are described in this and the following paragraphs [0XXX] through [0XYZ].
33-1	6079-6088	Therefore	_	_	
33-2	6088-6089	,	_	_	
33-3	6090-6093	the	_	_	
33-4	6094-6098	need	_	_	
33-5	6099-6107	persists	_	_	
33-6	6108-6114	beyond	_	_	
33-7	6115-6119	what	_	_	
33-8	6120-6122	is	_	_	
33-9	6123-6132	available	_	_	
33-10	6133-6135	in	_	_	
33-11	6136-6139	the	_	_	
33-12	6140-6145	prior	_	_	
33-13	6146-6149	art	_	_	
33-14	6150-6153	for	_	_	
33-15	6154-6155	a	_	_	
33-16	6156-6162	widely	_	_	
33-17	6163-6170	useable	_	_	
33-18	6171-6177	method	_	_	
33-19	6178-6181	for	_	_	
33-20	6182-6193	associating	_	_	
33-21	6194-6199	depth	_	_	
33-22	6200-6211	information	_	_	
33-23	6212-6216	with	_	_	
33-24	6217-6226	augmented	_	_	
33-25	6227-6234	reality	_	_	
33-26	6234-6235	.	_	_	
33-27	6236-6237	[	_	_	
33-28	6237-6241	0912	_	_	
33-29	6241-6242	]	_	_	
33-30	6243-6247	Some	_	_	
33-31	6248-6250	of	_	_	
33-32	6251-6254	the	_	_	
33-33	6255-6260	depth	_	_	
33-34	6261-6264	cue	_	_	
33-35	6265-6271	method	_	_	
33-36	6272-6283	embodiments	_	_	
33-37	6284-6286	of	_	_	
33-38	6287-6290	the	_	_	
33-39	6291-6298	present	_	_	
33-40	6299-6308	invention	_	_	
33-41	6309-6312	are	_	_	
33-42	6313-6322	described	_	_	
33-43	6323-6325	in	_	_	
33-44	6326-6330	this	_	_	
33-45	6331-6334	and	_	_	
33-46	6335-6338	the	_	_	
33-47	6339-6348	following	_	_	
33-48	6349-6359	paragraphs	_	_	
33-49	6360-6361	[	_	_	
33-50	6361-6365	0XXX	_	_	
33-51	6365-6366	]	_	_	
33-52	6367-6374	through	_	_	
33-53	6375-6376	[	_	_	
33-54	6376-6380	0XYZ	_	_	
33-55	6380-6381	]	_	_	
33-56	6381-6382	.	_	_	

#Text=Head mounted displays with see-through capabilities provide a clear view of the scene in front of the user while also providing the ability to display an image, where the user sees a combined image comprised of the see-through view with the display image overlaid.
34-1	6383-6387	Head	_	_	
34-2	6388-6395	mounted	_	_	
34-3	6396-6404	displays	_	_	
34-4	6405-6409	with	_	_	
34-5	6410-6421	see-through	_	_	
34-6	6422-6434	capabilities	_	_	
34-7	6435-6442	provide	_	_	
34-8	6443-6444	a	_	_	
34-9	6445-6450	clear	_	_	
34-10	6451-6455	view	_	_	
34-11	6456-6458	of	_	_	
34-12	6459-6462	the	_	_	
34-13	6463-6468	scene	_	_	
34-14	6469-6471	in	_	_	
34-15	6472-6477	front	_	_	
34-16	6478-6480	of	_	_	
34-17	6481-6484	the	_	_	
34-18	6485-6489	user	_	_	
34-19	6490-6495	while	_	_	
34-20	6496-6500	also	_	_	
34-21	6501-6510	providing	_	_	
34-22	6511-6514	the	_	_	
34-23	6515-6522	ability	_	_	
34-24	6523-6525	to	_	_	
34-25	6526-6533	display	_	_	
34-26	6534-6536	an	_	_	
34-27	6537-6542	image	_	_	
34-28	6542-6543	,	_	_	
34-29	6544-6549	where	_	_	
34-30	6550-6553	the	_	_	
34-31	6554-6558	user	_	_	
34-32	6559-6563	sees	_	_	
34-33	6564-6565	a	_	_	
34-34	6566-6574	combined	_	_	
34-35	6575-6580	image	_	_	
34-36	6581-6590	comprised	_	_	
34-37	6591-6593	of	_	_	
34-38	6594-6597	the	_	_	
34-39	6598-6609	see-through	_	_	
34-40	6610-6614	view	_	_	
34-41	6615-6619	with	_	_	
34-42	6620-6623	the	_	_	
34-43	6624-6631	display	_	_	
34-44	6632-6637	image	_	_	
34-45	6638-6646	overlaid	_	_	
34-46	6646-6647	.	_	_	

#Text=The methods are entail the displaying of 3D labels and other 3D information using the see-through display to aid the user in interpreting the environment surrounding the user.
35-1	6648-6651	The	_	_	
35-2	6652-6659	methods	_	_	
35-3	6660-6663	are	_	_	
35-4	6664-6670	entail	_	_	
35-5	6671-6674	the	_	_	
35-6	6675-6685	displaying	_	_	
35-7	6686-6688	of	_	_	
35-8	6689-6691	3D	_	_	
35-9	6692-6698	labels	_	_	
35-10	6699-6702	and	_	_	
35-11	6703-6708	other	_	_	
35-12	6709-6711	3D	_	_	
35-13	6712-6723	information	_	_	
35-14	6724-6729	using	_	_	
35-15	6730-6733	the	_	_	
35-16	6734-6745	see-through	_	_	
35-17	6746-6753	display	_	_	
35-18	6754-6756	to	_	_	
35-19	6757-6760	aid	_	_	
35-20	6761-6764	the	_	_	
35-21	6765-6769	user	_	_	
35-22	6770-6772	in	_	_	
35-23	6773-6785	interpreting	_	_	
35-24	6786-6789	the	_	_	
35-25	6790-6801	environment	_	_	
35-26	6802-6813	surrounding	_	_	
35-27	6814-6817	the	_	_	
35-28	6818-6822	user	_	_	
35-29	6822-6823	.	_	_	

#Text=A stereo pair of images of the 3D labels and other 3D information may be presented to the left and right eyes of the user to position the 3D labels and other 3D information at different depths in the scene as perceived by the user.
36-1	6824-6825	A	_	_	
36-2	6826-6832	stereo	_	_	
36-3	6833-6837	pair	_	_	
36-4	6838-6840	of	_	_	
36-5	6841-6847	images	_	_	
36-6	6848-6850	of	_	_	
36-7	6851-6854	the	_	_	
36-8	6855-6857	3D	_	_	
36-9	6858-6864	labels	_	_	
36-10	6865-6868	and	_	_	
36-11	6869-6874	other	_	_	
36-12	6875-6877	3D	_	_	
36-13	6878-6889	information	_	_	
36-14	6890-6893	may	_	_	
36-15	6894-6896	be	_	_	
36-16	6897-6906	presented	_	_	
36-17	6907-6909	to	_	_	
36-18	6910-6913	the	_	_	
36-19	6914-6918	left	_	_	
36-20	6919-6922	and	_	_	
36-21	6923-6928	right	_	_	
36-22	6929-6933	eyes	_	_	
36-23	6934-6936	of	_	_	
36-24	6937-6940	the	_	_	
36-25	6941-6945	user	_	_	
36-26	6946-6948	to	_	_	
36-27	6949-6957	position	_	_	
36-28	6958-6961	the	_	_	
36-29	6962-6964	3D	_	_	
36-30	6965-6971	labels	_	_	
36-31	6972-6975	and	_	_	
36-32	6976-6981	other	_	_	
36-33	6982-6984	3D	_	_	
36-34	6985-6996	information	_	_	
36-35	6997-6999	at	_	_	
36-36	7000-7009	different	_	_	
36-37	7010-7016	depths	_	_	
36-38	7017-7019	in	_	_	
36-39	7020-7023	the	_	_	
36-40	7024-7029	scene	_	_	
36-41	7030-7032	as	_	_	
36-42	7033-7042	perceived	_	_	
36-43	7043-7045	by	_	_	
36-44	7046-7049	the	_	_	
36-45	7050-7054	user	_	_	
36-46	7054-7055	.	_	_	

#Text=In this way the 3D labels and other 3D information can be more easily associated with the see-through view and the surrounding environment.
37-1	7056-7058	In	_	_	
37-2	7059-7063	this	_	_	
37-3	7064-7067	way	_	_	
37-4	7068-7071	the	_	_	
37-5	7072-7074	3D	_	_	
37-6	7075-7081	labels	_	_	
37-7	7082-7085	and	_	_	
37-8	7086-7091	other	_	_	
37-9	7092-7094	3D	_	_	
37-10	7095-7106	information	_	_	
37-11	7107-7110	can	_	_	
37-12	7111-7113	be	_	_	
37-13	7114-7118	more	_	_	
37-14	7119-7125	easily	_	_	
37-15	7126-7136	associated	_	_	
37-16	7137-7141	with	_	_	
37-17	7142-7145	the	_	_	
37-18	7146-7157	see-through	_	_	
37-19	7158-7162	view	_	_	
37-20	7163-7166	and	_	_	
37-21	7167-7170	the	_	_	
37-22	7171-7182	surrounding	_	_	
37-23	7183-7194	environment	_	_	
37-24	7194-7195	.	_	_	
