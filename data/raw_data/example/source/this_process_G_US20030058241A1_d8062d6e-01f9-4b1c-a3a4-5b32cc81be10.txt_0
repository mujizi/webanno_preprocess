[0036] In three-dimensional graphics applications, objects in a scene are represented by three-dimensional graphical models, which include geometric data used to model the surface and position of the objects, and visual attributes used to model their appearance. There are a number of ways that a geometric model can represent a three-dimensional object, including polygon meshes, parametric surfaces, or quadratic surfaces. The surface elements, such as polygons, are referred to as geometric primitives. Visual attributes such as red, green, and blue color data, and possibly other model data, are typically stored in a data structure representing the vertices of the polygons.
[0037] In the rendering process, the geometric primitives corresponding to objects in a scene are processed to generate a display image. In the context of three-dimensional graphics, the rendering process includes transforming the objects to display device coordinates, and rasterizing the geometric primitives in the models to generate pixel values for the pixel elements of a display image. Potentially visible objects in a particular scene are identified by transforming objects into a common three-dimensional coordinate system and then determining whether the objects overlap a view volume, which is a three-dimensional space defining the bounds of a scene. The geometric primitives of potentially visible objects are then transformed to display device coordinates and rasterized into pixel data. Before rasterizing the primitives, it is common to eliminate surfaces that face away from the viewpoint in a process known as "backface culling."
[0038] Rasterizing generally refers to the process of computing a pixel value for a pixel based on data from the geometric primitives that project onto or "cover" the pixel. As part of the rendering process, hidden surface removal is performed on the potentially visible objects in a scene. Objects are referred to as potentially visible because they reside in or overlap the view volume. However, some of the objects or parts of objects in the view volume will not be represented in the rendered image because they are blocked or occluded by other objects. Hidden surface removal refers to the process of determining which objects or portions of objects are, and conversely, are not, visible in the scene. During this process, the graphics system determines which objects or portions are visible from the viewpoint.
[0039] One approach to hidden surface removal is referred to as the z-buffer algorithm. In this approach, a "z-buffer" is used to perform hidden surface removal on pixel data generated as primitives are rasterized. The letter "z" refers to a depth value and originates from the common practice of expressing distance from the viewpoint using the z-axis in a three-dimensional coordinate system. The z-buffer is used to store pixels closest to the viewpoint for each pixel location in an image. As a primitive is rasterized, pixel data including a depth value is generated. The depth of a newly generated pixel is compared with a pixel stored in the z-buffer for the same pixel location. If the newly generated pixel is further from the view point than the stored pixel, it is rejected. If not, it replaces the pixel stored in the z-buffer. This process continues until an entire frame of pixels is generated.
[0040] Just as objects can occlude other objects from the perspective of the view point, some objects can occlude other objects from the perspective of a light source. In this case, objects closer to the light source can cast a shadow on other objects in the scene. "Shadowing" refers to the process of determining which objects are shadowed and then representing those shadows in a rendered image.